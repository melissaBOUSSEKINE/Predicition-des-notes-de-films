{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11bca92",
   "metadata": {
    "id": "f11bca92"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import operator as op\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba07b3",
   "metadata": {
    "id": "c9ba07b3"
   },
   "outputs": [],
   "source": [
    "#chargement des donnes\n",
    "liste_id = []\n",
    "liste_label = []\n",
    "liste_message = []\n",
    "file_train = '/content/drive/My Drive/Analyse_des_sentiment/data/train.xml'\n",
    "file_dev   = '/content/drive/My Drive/Analyse_des_sentiment/data/dev.xml'\n",
    "file_test  = '/content/drive/My Drive/Analyse_des_sentiment/data/test.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GmXrAP6zaR6t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GmXrAP6zaR6t",
    "outputId": "941fb48c-3d7d-4217-f007-23dd4295e8df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0de961",
   "metadata": {
    "id": "4f0de961"
   },
   "outputs": [],
   "source": [
    "def read_xml_to_dataframe(file_path):\n",
    "    # Analyse du fichier XML\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Création d'une liste vide pour stocker les données\n",
    "    data = []\n",
    "\n",
    "    # Parcours des éléments de commentaire\n",
    "    for comment in root.findall('comment'):\n",
    "        movie = comment.find('movie').text\n",
    "        review_id = comment.find('review_id').text\n",
    "        name = comment.find('name').text\n",
    "        user_id = comment.find('user_id').text\n",
    "        note = comment.find('note').text.replace(',', '.')\n",
    "        commentaire = comment.find('commentaire').text\n",
    "\n",
    "        # Ajout des données dans la liste sous forme de dictionnaire\n",
    "        data.append({\n",
    "            'movie': movie,\n",
    "            'review_id': review_id,\n",
    "            'name': name,\n",
    "            'user_id': user_id,\n",
    "            'note': note,\n",
    "            'commentaire': commentaire\n",
    "        })\n",
    "\n",
    "    # Création d'un DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fff348",
   "metadata": {
    "id": "03fff348"
   },
   "outputs": [],
   "source": [
    "#fonction pour le fichier de test\n",
    "def read_xml_to_dataframeTest(file_path):\n",
    "    # Analyse du fichier XML\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Création d'une liste vide pour stocker les données\n",
    "    data = []\n",
    "\n",
    "    # Parcours des éléments de commentaire\n",
    "    for comment in root.findall('comment'):\n",
    "        # Initialisation d'un dictionnaire pour chaque commentaire\n",
    "        comment_data = {}\n",
    "\n",
    "        # Extraction de chaque élément si disponible et ajout au dictionnaire\n",
    "        movie = comment.find('movie')\n",
    "        if movie is not None:\n",
    "            comment_data['movie'] = movie.text\n",
    "\n",
    "        review_id = comment.find('review_id')\n",
    "        if review_id is not None:\n",
    "            comment_data['review_id'] = review_id.text\n",
    "\n",
    "        name = comment.find('name')\n",
    "        if name is not None:\n",
    "            comment_data['name'] = name.text\n",
    "\n",
    "        user_id = comment.find('user_id')\n",
    "        if user_id is not None:\n",
    "            comment_data['user_id'] = user_id.text\n",
    "\n",
    "        # Note is not present in the given data, but if it's sometimes included,\n",
    "        # you can check for it like this:\n",
    "        note = comment.find('note')\n",
    "        if note is not None:\n",
    "            comment_data['note'] = note.text.replace(',', '.')\n",
    "\n",
    "        commentaire = comment.find('commentaire')\n",
    "        if commentaire is not None:\n",
    "            comment_data['commentaire'] = commentaire.text\n",
    "\n",
    "        # Ajout des données dans la liste sous forme de dictionnaire\n",
    "        data.append(comment_data)\n",
    "\n",
    "    # Création d'un DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3d295",
   "metadata": {
    "id": "74f3d295"
   },
   "source": [
    "# Récupération des données dans des dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453b5f6",
   "metadata": {
    "id": "f453b5f6"
   },
   "outputs": [],
   "source": [
    "#création DataFrame\n",
    "data_dev   = read_xml_to_dataframe(file_dev)\n",
    "data_train = read_xml_to_dataframe(file_train)\n",
    "data_test  = read_xml_to_dataframeTest(file_test)\n",
    "\n",
    "data_train['commentaire'] = data_train['commentaire'].fillna('')\n",
    "data_dev['commentaire'] = data_dev['commentaire'].fillna('')\n",
    "data_test['commentaire'] = data_test['commentaire'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076227c",
   "metadata": {
    "id": "1076227c"
   },
   "outputs": [],
   "source": [
    "data_train['note'] = pd.to_numeric(data_train['note'], errors='coerce')\n",
    "data_dev['note'] = pd.to_numeric(data_dev['note'], errors='coerce')\n",
    "data_train['note'] = data_train['note'].apply(lambda x: x * 2)\n",
    "data_dev['note'] = data_dev['note'].apply(lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f93187",
   "metadata": {
    "id": "11f93187"
   },
   "outputs": [],
   "source": [
    "data_test  = read_xml_to_dataframeTest(file_test)\n",
    "data_test['commentaire'] = data_test['commentaire'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c26c899",
   "metadata": {
    "id": "4c26c899"
   },
   "outputs": [],
   "source": [
    "Y_train  = data_train['note']\n",
    "y_train_adjusted = Y_train - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sCiqcBOA387V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCiqcBOA387V",
    "outputId": "6360ff6f-949e-447a-e776-7313536ed9ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100400,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dev  = data_dev['note']\n",
    "y_dev_adjusted = Y_dev - 1\n",
    "y_dev_adjusted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hAWq_lZMTA8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAWq_lZMTA8b",
    "outputId": "4ddd3cba-18c9-4e55-91d9-916729b560d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665962,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_adjusted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hw14JLAuOYbd",
   "metadata": {
    "id": "hw14JLAuOYbd"
   },
   "source": [
    "### **Prétraitement des Commentaires Textuels avec Keras : Tokenisation et Remplissage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83271378",
   "metadata": {
    "id": "83271378"
   },
   "outputs": [],
   "source": [
    "#\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "\n",
    "# Initialiser le tokenizer de Keras\n",
    "tokenizer = Tokenizer(num_words=5000)  \n",
    "tokenizer.fit_on_texts(data_train['commentaire'])\n",
    "\n",
    "# Convertir les commentaires en séquences d'entiers\n",
    "X_train = tokenizer.texts_to_sequences(data_train['commentaire'])\n",
    "\n",
    "# Définir une longueur maximale\n",
    "MAX_LENGTH = 500\n",
    "\n",
    "# Padding et troncature des vecteurs\n",
    "X_train_padded = pad_sequences(X_train, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "# Affichage du résultat\n",
    "X_train_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TCRqzAbz3dCG",
   "metadata": {
    "id": "TCRqzAbz3dCG"
   },
   "outputs": [],
   "source": [
    "# Convertir les commentaires en séquences d'entiers\n",
    "X_dev = tokenizer.texts_to_sequences(data_dev['commentaire'])\n",
    "\n",
    "# Padding et troncature des vecteurs\n",
    "X_dev_padded = pad_sequences(X_dev, maxlen=MAX_LENGTH, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ilYgeJqf26LA",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilYgeJqf26LA",
    "outputId": "0b31db03-760e-4342-83de-1620e45231fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 1.8027, Validation Loss: 2.4517, Accuracy: 0.1711\n",
      "Epoch [2/10], Training Loss: 1.4614, Validation Loss: 2.5105, Accuracy: 0.1735\n",
      "Epoch [3/10], Training Loss: 1.4105, Validation Loss: 2.7127, Accuracy: 0.1479\n",
      "Epoch [4/10], Training Loss: 1.3797, Validation Loss: 2.5755, Accuracy: 0.1623\n",
      "Epoch [5/10], Training Loss: 1.3562, Validation Loss: 2.6092, Accuracy: 0.1620\n",
      "Epoch [6/10], Training Loss: 1.3360, Validation Loss: 2.7017, Accuracy: 0.1598\n",
      "Epoch [7/10], Training Loss: 1.3175, Validation Loss: 2.7745, Accuracy: 0.1586\n",
      "Epoch [8/10], Training Loss: 1.3007, Validation Loss: 2.7472, Accuracy: 0.1573\n",
      "Epoch [9/10], Training Loss: 1.2865, Validation Loss: 2.7999, Accuracy: 0.1577\n",
      "Epoch [10/10], Training Loss: 1.2741, Validation Loss: 2.9094, Accuracy: 0.1529\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Classe du modèle LSTM\n",
    "class CommentClassifierLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, embed_size, num_layers):\n",
    "        super(CommentClassifierLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]  # Prendre la dernière sortie de la séquence\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Paramètres du modèle \n",
    "input_size = 10000  # Taille du vocabulaire \n",
    "embed_size = 100  # Taille des embeddings\n",
    "hidden_size = 128  # Taille des couches cachées LSTM\n",
    "num_classes = 10  # Nombre de classes de sortie\n",
    "num_layers = 2  # Nombre de couches LSTM\n",
    "\n",
    "# Création du modèle et passage au GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CommentClassifierLSTM(input_size, hidden_size, num_classes, embed_size, num_layers).to(device)\n",
    "\n",
    "# Définir la fonction de perte et l'optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Convertir en tenseurs\n",
    "X_train_tensor = torch.tensor(X_train_padded, dtype=torch.long).to(device)\n",
    "y_train_tensor = torch.tensor(y_train_adjusted, dtype=torch.long).to(device)\n",
    "X_val_tensor = torch.tensor(X_dev_padded, dtype=torch.long).to(device)\n",
    "y_val_tensor = torch.tensor(y_dev_adjusted, dtype=torch.long).to(device)\n",
    "\n",
    "# Création des DataLoaders pour l'entraînement et la validation\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Boucle d'entraînement avec validation\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        # Entraînement\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {total_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {correct / total:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rRHLv96eTS3L",
   "metadata": {
    "id": "rRHLv96eTS3L"
   },
   "source": [
    "### **Tf_IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AUs0vpg7TJdb",
   "metadata": {
    "id": "AUs0vpg7TJdb"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/content/drive/My Drive/Analyse_des_sentiment/data/dataTF/tfidf_dev.pkl', 'rb') as f:\n",
    "    X_dev_padded  = pickle.load(f)\n",
    "\n",
    "with open('/content/drive/My Drive/Analyse_des_sentiment/data/dataTF/tfidf_train.pkl', 'rb') as f:\n",
    "     X_train_padded = pickle.load(f)\n",
    "\n",
    "with open('/content/drive/My Drive/Analyse_des_sentiment/data/dataTF/tfidf_test.pkl', 'rb') as f:\n",
    "    X_test_padded  = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VRzLJSwSTN1Q",
   "metadata": {
    "id": "VRzLJSwSTN1Q"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Classe du modèle LSTM\n",
    "class CommentClassifierLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, embed_size, num_layers):\n",
    "        super(CommentClassifierLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]  # Prendre la dernière sortie de la séquence\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Paramètres du modèle\n",
    "input_size = 10000  # Taille du vocabulaire \n",
    "embed_size = 100  # Taille des embeddings\n",
    "hidden_size = 128  # Taille des couches cachées LSTM\n",
    "num_classes = 10  # Nombre de classes de sortie\n",
    "num_layers = 2  # Nombre de couches LSTM\n",
    "\n",
    "# Création du modèle et passage au GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CommentClassifierLSTM(input_size, hidden_size, num_classes, embed_size, num_layers).to(device)\n",
    "\n",
    "# Définir la fonction de perte et l'optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "X_train_dense = X_train_padded.toarray()  \n",
    "\n",
    "# Convertir y_train_adjusted en un tableau numpy\n",
    "y_train_numpy = y_train_adjusted.values \n",
    "\n",
    "# Convertir les tableaux numpy dense en tenseurs PyTorch\n",
    "X_train_tensor = torch.tensor(X_train_dense, dtype=torch.long).to(device)\n",
    "y_train_tensor = torch.tensor(y_train_numpy, dtype=torch.long).to(device)\n",
    "\n",
    "# Création du DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "# Boucle d'entraînement\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RhHtCI93fE-N",
   "metadata": {
    "id": "RhHtCI93fE-N"
   },
   "source": [
    "#**Bert-base-uncased**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XASBN0ize6z-",
   "metadata": {
    "id": "XASBN0ize6z-"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Initialisation du tokenizer et du modèle\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Vérifier si un GPU est disponible et le configurer pour le modèle\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d13f5",
   "metadata": {
    "id": "629d13f5"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(texts, max_length=500):\n",
    "    # Tronquer les textes si leur longueur dépasse max_length\n",
    "    truncated_texts = [text[:max_length] for text in texts]\n",
    "\n",
    "    # Préparer les inputs pour le modèle et les déplacer sur le GPU\n",
    "    inputs = tokenizer(truncated_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_length)\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Exécuter le modèle sur le GPU\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Ramener les embeddings sur le CPU et les convertir en NumPy\n",
    "    return outputs.last_hidden_state[:, 0, :].cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bOWfDR2ncoh1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOWfDR2ncoh1",
    "outputId": "c443e14c-41e6-4afe-a898-4f8ba2f1096d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665962,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appliquer la fonction à la colonne de texte du DataFrame\n",
    "data_train['embeddings'] = data_train['commentaire'].apply(lambda x: get_embeddings([x]))\n",
    "data_train['embeddings'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OIt8gt8ycqsv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIt8gt8ycqsv",
    "outputId": "07a15a5b-77ed-46a6-9888-dd21161a004e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85847,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['embeddings'] = data_test['commentaire'].apply(lambda x: get_embeddings([x]))\n",
    "data_test['embeddings'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jGKuGLnACycB",
   "metadata": {
    "id": "jGKuGLnACycB"
   },
   "outputs": [],
   "source": [
    "X_train_padded = data_train['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wua54nlFDYfE",
   "metadata": {
    "id": "wua54nlFDYfE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convertir les données en tenseurs PyTorch et les transférer sur le bon appareil\n",
    "X_train_tensor = torch.tensor(X_train_padded, dtype=torch.float).to(device)\n",
    "y_train_tensor = torch.tensor(y_train_adjusted, dtype=torch.long).to(device)\n",
    "\n",
    "# Créer un DataLoader pour le traitement par lots\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VH9YkMQIEwve",
   "metadata": {
    "id": "VH9YkMQIEwve"
   },
   "source": [
    "# **LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EKNUI7quEwWz",
   "metadata": {
    "id": "EKNUI7quEwWz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class CommentClassifierLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes, num_layers, input_dim):\n",
    "        super(CommentClassifierLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_size, num_layers, batch_first=True, dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]  # Prendre la dernière sortie de la séquence\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4Fg6FHV-FX0l",
   "metadata": {
    "id": "4Fg6FHV-FX0l"
   },
   "outputs": [],
   "source": [
    "input_dim = 768  # Taille des embeddings\n",
    "hidden_size = 128  # Taille des couches cachées LSTM\n",
    "num_classes = 10  # Nombre de classes de sortie \n",
    "num_layers = 2  # Nombre de couches LSTM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CommentClassifierLSTM(hidden_size, num_classes, num_layers, input_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3XuMmahnFajt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3XuMmahnFajt",
    "outputId": "3209a58a-d012-4574-933e-7e9066cdc175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.0454\n",
      "Epoch [2/10], Loss: 2.0045\n",
      "Epoch [3/10], Loss: 1.9907\n",
      "Epoch [4/10], Loss: 1.9827\n",
      "Epoch [5/10], Loss: 1.9764\n",
      "Epoch [6/10], Loss: 1.9719\n",
      "Epoch [7/10], Loss: 1.9677\n",
      "Epoch [8/10], Loss: 1.9640\n",
      "Epoch [9/10], Loss: 1.9615\n",
      "Epoch [10/10], Loss: 1.9585\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XXALMsXqF7d0",
   "metadata": {
    "id": "XXALMsXqF7d0"
   },
   "outputs": [],
   "source": [
    "X_test_padded = data_test['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ik_pk1chFsSc",
   "metadata": {
    "id": "ik_pk1chFsSc"
   },
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test_padded, dtype=torch.float).to(device)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YH45sNQyGTaD",
   "metadata": {
    "id": "YH45sNQyGTaD"
   },
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs[0]  \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    return predictions\n",
    "\n",
    "predictions = predict(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c0151",
   "metadata": {
    "id": "b53c0151"
   },
   "outputs": [],
   "source": [
    "# Ajouter les prédictions ajustées comme une nouvelle colonne à data_test\n",
    "predictions_series = pd.Series(predictions)\n",
    "adjusted_predictions = (predictions_series + 1) / 2\n",
    "data_test['note'] = adjusted_predictions\n",
    "dataTest = data_test\n",
    "dataTest\n",
    "import pandas as pd\n",
    "\n",
    "# Fonction pour convertir un nombre flottant en chaîne avec une virgule pour le décimal\n",
    "def float_to_comma_string(x):\n",
    "    if isinstance(x, float):\n",
    "        return '{:.1f}'.format(x).replace('.', ',')\n",
    "    return x\n",
    "\n",
    "# Convertir les notes (prédictions) en nombres\n",
    "data_test['note'] = data_test['note'].apply(float_to_comma_string)\n",
    "\n",
    "# Fusionner les prédictions avec review_id\n",
    "df_test = pd.concat([data_test['review_id'], data_test['note']], axis=1)\n",
    "\n",
    "# Enregistrer dans un nouveau fichier texte séparé par un espace\n",
    "df_test.to_csv('/content/drive/My Drive/Analyse_des_sentiment/data/test_output_LSTM_Embeding.txt', sep=' ', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
