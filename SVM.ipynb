{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f11bca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import operator as op\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9ba07b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement des donnes \n",
    "liste_id = []\n",
    "liste_label = []\n",
    "liste_message = []\n",
    "file_train = 'data/train.xml'\n",
    "file_dev   = 'data/dev.xml'\n",
    "file_test  = 'data/test.xml' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f0de961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml_to_dataframe(file_path):\n",
    "    # Analyse du fichier XML\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Création d'une liste vide pour stocker les données\n",
    "    data = []\n",
    "\n",
    "    # Parcours des éléments de commentaire\n",
    "    for comment in root.findall('comment'):\n",
    "        movie = comment.find('movie').text\n",
    "        review_id = comment.find('review_id').text\n",
    "        name = comment.find('name').text\n",
    "        user_id = comment.find('user_id').text\n",
    "        note = comment.find('note').text.replace(',', '.')\n",
    "        commentaire = comment.find('commentaire').text\n",
    "\n",
    "        # Ajout des données dans la liste sous forme de dictionnaire\n",
    "        data.append({\n",
    "            'movie': movie,\n",
    "            'review_id': review_id,\n",
    "            'name': name,\n",
    "            'user_id': user_id,\n",
    "            'note': note,\n",
    "            'commentaire': commentaire\n",
    "        })\n",
    "\n",
    "    # Création d'un DataFrame \n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03fff348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction pour le fichier de test \n",
    "def read_xml_to_dataframeTest(file_path):\n",
    "    # Analyse du fichier XML\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Création d'une liste vide pour stocker les données\n",
    "    data = []\n",
    "\n",
    "    # Parcours des éléments de commentaire\n",
    "    for comment in root.findall('comment'):\n",
    "        # Initialisation d'un dictionnaire pour chaque commentaire\n",
    "        comment_data = {}\n",
    "\n",
    "        # Extraction de chaque élément si disponible et ajout au dictionnaire\n",
    "        movie = comment.find('movie')\n",
    "        if movie is not None:\n",
    "            comment_data['movie'] = movie.text\n",
    "\n",
    "        review_id = comment.find('review_id')\n",
    "        if review_id is not None:\n",
    "            comment_data['review_id'] = review_id.text\n",
    "\n",
    "        name = comment.find('name')\n",
    "        if name is not None:\n",
    "            comment_data['name'] = name.text\n",
    "\n",
    "        user_id = comment.find('user_id')\n",
    "        if user_id is not None:\n",
    "            comment_data['user_id'] = user_id.text\n",
    "\n",
    "        # Note is not present in the given data, but if it's sometimes included,\n",
    "        # you can check for it like this:\n",
    "        note = comment.find('note')\n",
    "        if note is not None:\n",
    "            comment_data['note'] = note.text.replace(',', '.')\n",
    "\n",
    "        commentaire = comment.find('commentaire')\n",
    "        if commentaire is not None:\n",
    "            comment_data['commentaire'] = commentaire.text\n",
    "\n",
    "        # Ajout des données dans la liste sous forme de dictionnaire\n",
    "        data.append(comment_data)\n",
    "\n",
    "    # Création d'un DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3d295",
   "metadata": {},
   "source": [
    "# Récupération des données dans des dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f453b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#création DataFrame\n",
    "data_dev   = read_xml_to_dataframe(file_dev)\n",
    "data_train = read_xml_to_dataframe(file_train)\n",
    "data_test  = read_xml_to_dataframeTest(file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23098bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\"creation de lexique###############\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lexique_(message):\n",
    "    lexique =[]\n",
    "    lexique_unique = []\n",
    "    for m in range(len(message)):\n",
    "        liste = nltk.word_tokenize(message[m],language=\"french\")   \n",
    "        for  i in liste:\n",
    "            lexique.append(lemmatizer.lemmatize(i))\n",
    "        #####lexique unique###\n",
    "    for i in range(len(lexique)):\n",
    "        if lexique[i] not in lexique_unique :\n",
    "            lexique_unique.append(lexique[i])\n",
    "    return lexique_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf5629a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Table de H################\n",
    "def table_h(lexique_unique):\n",
    "    h = {}\n",
    "    i = 0\n",
    "    for mot in lexique_unique:\n",
    "       h[mot] = i\n",
    "       i+=1\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6afc3085",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################Matrice#######################\n",
    "def matrice(message,lexique_unique):\n",
    "    h = table_h(lexique_unique)\n",
    "    nombre_lignes = message.shape[0]\n",
    "    nombre_colones = len(h)\n",
    "    m = np.zeros((nombre_lignes,nombre_colones))\n",
    "    \n",
    "    for i in range(nombre_lignes):\n",
    "       #print(\"i\",i)\n",
    "        for mot in lexique_unique:\n",
    "            j = h[mot]\n",
    "            #nombre d'occurence de mot dans message [i]\n",
    "            mot = mot+\" \"\n",
    "            nombre_occurence =  message[i].count(mot)\n",
    "            m[i,j] =  nombre_occurence\n",
    "              \n",
    "    print(\"fin de la foncrion\\n\") \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48127398",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################SVM############################\n",
    "def convertir_svm(matrice, etiquettes):\n",
    "    # Initialisation de la chaîne de caractères qui contiendra le fichier SVM\n",
    "    svm = \"\"\n",
    "\n",
    "    # Parcourt de la matrice de données \n",
    "    for i in range(matrice.shape[0]):\n",
    "        # Ajout de l'étiquette de la classe en début de ligne\n",
    "        svm += str(etiquettes[i]) + \" \"\n",
    "        # Parcourt de chaque colonne de la ligne courante\n",
    "        for j in range(matrice.shape[1]):\n",
    "            # Si la valeur de la caractéristique est non nulle\n",
    "            if matrice[i, j] != 0:\n",
    "                svm += f\"{j+1}:{matrice[i, j]} \"\n",
    "        # Ajout du retour à la ligne à la fin de la ligne courante\n",
    "        svm += \"\\n\"\n",
    "    \n",
    "    return svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68cd4640",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "def file(nom,contenu):\n",
    "    \n",
    "    # Ouvrez le fichier en mode écriture\n",
    "    with io.open(nom, \"w\", encoding=\"utf-8\") as f:\n",
    "        # Écrivez vos lignes de string dans le fichier\n",
    "        f.writelines(contenu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbd56270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupération des commentaire\n",
    "message_test = np.array(data_test['commentaire'])\n",
    "message_dev = np.array(data_dev['commentaire'])\n",
    "message_train = np.array(data_train['commentaire'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8582897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\etudiant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def lexique_(messages):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lexique = set()\n",
    "\n",
    "    for message in messages:\n",
    "        if message is not None:  # Vérifiez que le message n'est pas None\n",
    "            tokens = word_tokenize(message, language=\"french\")\n",
    "            for token in tokens:\n",
    "                lexique.add(lemmatizer.lemmatize(token))\n",
    "\n",
    "    return list(lexique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d51b7ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation de lexique\n",
    "lexique_unique = lexique_(message_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e75abc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['traduisit',\n",
       " 'Pic',\n",
       " 'mono-parentales',\n",
       " \"s'accomplit\",\n",
       " 'incontestable…',\n",
       " 'percevérance',\n",
       " \"L'aversion\",\n",
       " 'Moriarty-Cassady',\n",
       " 'moyen.Selon',\n",
       " 'pâlira',\n",
       " 'Ensuite',\n",
       " 'quelques',\n",
       " \"l'arrangera\",\n",
       " 'France.Sincèrement',\n",
       " 'acupuncteur',\n",
       " 'klapishiens',\n",
       " 'NewYork',\n",
       " 'hyper-saturées',\n",
       " 'aneaux',\n",
       " 'dévaliser',\n",
       " 'Latinos',\n",
       " 'winstherpoon',\n",
       " 'nègociateur',\n",
       " 'cornichonnerie',\n",
       " 'formèrent',\n",
       " 'Matriochka',\n",
       " 'fatigués',\n",
       " 'Assassinats',\n",
       " 'poétisée',\n",
       " 'Jaques-Yves',\n",
       " 'trouvables',\n",
       " 'Dawe',\n",
       " 'Stapple',\n",
       " 'machinéen',\n",
       " 'aménées',\n",
       " 'ni-plus',\n",
       " 'reboots/remakes/spin-offs',\n",
       " 'tortueuse',\n",
       " 'Schwarziennes',\n",
       " 'sur-dosées',\n",
       " 'grimait',\n",
       " 'Évitable',\n",
       " 'blockbuster^^',\n",
       " '//www.cineserie.com/dossiers/gros-plan/gros-plan-john-wick-retour-sur-une-des-meilleures-sagas-daction-contemporaines-2549560/',\n",
       " 'rembourrage',\n",
       " \"L'escalavage\",\n",
       " 'offrirai',\n",
       " 'effectués',\n",
       " 'blondeur',\n",
       " 'emennant',\n",
       " 'zappette',\n",
       " 'protectrices',\n",
       " 'menace…',\n",
       " 'bisexuelle',\n",
       " 'satiriser',\n",
       " 'polygamie',\n",
       " 'Retro',\n",
       " 'blafarde.Pas',\n",
       " 'Alexsandr',\n",
       " 'maxamovies',\n",
       " '8-o',\n",
       " 'comedie/action/nanard',\n",
       " 'arrosement',\n",
       " '//www.facebook.com/critiquedefilmsdhorreur/',\n",
       " \"quarts-d'heure\",\n",
       " 'vieillissons',\n",
       " 'cartésianisme',\n",
       " 'rêvassant',\n",
       " \"'Us\",\n",
       " \"comprend.D'ailleurs\",\n",
       " '������🤗�',\n",
       " 'admiarablement',\n",
       " \"s'appartient\",\n",
       " 'intrêt',\n",
       " 'éfets',\n",
       " \"l'invocation\",\n",
       " 'bleffant',\n",
       " \"dramatique.L'impression\",\n",
       " 'PEYRAC',\n",
       " 'sagira',\n",
       " \"d'hominidés\",\n",
       " 'encaissées',\n",
       " 'S.Azéma',\n",
       " \"s'écrivent\",\n",
       " '//clairedanslessallesobscures.over-blog.com/article-la-guerre-est-declaree-84787816.html',\n",
       " 'TANG',\n",
       " 'tard.Pour',\n",
       " 'parivent',\n",
       " 'contrôles',\n",
       " \"presqu'irréaliste\",\n",
       " 'écrira-t-il',\n",
       " 'Whitworth',\n",
       " 'començait',\n",
       " '1910.',\n",
       " 'I.CARRE',\n",
       " 'Fourmidable',\n",
       " '100k',\n",
       " 'callanque',\n",
       " 'éleves',\n",
       " 'malcolm',\n",
       " 'kickboxers',\n",
       " 'plâtrière',\n",
       " 'commun2C2C',\n",
       " 'voir^^',\n",
       " 'B.13',\n",
       " 'PATHETIQUE',\n",
       " 'réhumanisation',\n",
       " 'allourdir',\n",
       " 'glaçés',\n",
       " 'déconseilleront',\n",
       " 'bestiasse',\n",
       " 'Mentionnons',\n",
       " 'défouraillages',\n",
       " 'pétroleuse',\n",
       " 'scènes-à-sursaut',\n",
       " 'réalisateurs/réalisatrices',\n",
       " 'samoa',\n",
       " 'sauter/exploser',\n",
       " 'finirons',\n",
       " 'Cailley',\n",
       " 'Snowdon',\n",
       " 'DORKEL',\n",
       " 'tagger',\n",
       " \"s'organisait\",\n",
       " 'éjac',\n",
       " \"Qu'est-ce-qui\",\n",
       " 'récupérons',\n",
       " 'sauve-qui-peut',\n",
       " 'survitaminté',\n",
       " 'néo-',\n",
       " 'Sieg',\n",
       " 'Défaillante',\n",
       " \"Qu'aime-t-on\",\n",
       " 'tout….A',\n",
       " 'gillet',\n",
       " 'Daniel/le',\n",
       " 'genrall',\n",
       " 'eXtase',\n",
       " 'incomprensibles',\n",
       " 'patou',\n",
       " 'stéréoscopique',\n",
       " 'DELEVINGNE',\n",
       " 'POURRI',\n",
       " 'échelle…avec',\n",
       " 'articiel',\n",
       " 'enlaidis',\n",
       " 'moitié/dernier',\n",
       " 'Baer/Magimel',\n",
       " 'Infidéles',\n",
       " 'zoms',\n",
       " 'colonnade',\n",
       " 'original.Dans',\n",
       " 'Fictive-Thriller',\n",
       " 'chaste',\n",
       " 'REBECCA',\n",
       " 'Dargen',\n",
       " 'Bordage',\n",
       " 'mieux/',\n",
       " 'MIKKELSEN',\n",
       " \"d'entraineur\",\n",
       " 'thanos',\n",
       " 'quasi-mythique',\n",
       " '-2011',\n",
       " \"s'encombrer\",\n",
       " 'dècliner',\n",
       " 'BlackBox',\n",
       " 'Philosophiquement',\n",
       " 'Mikelsen',\n",
       " 'Spillneir',\n",
       " 'vision/adaptation',\n",
       " 'Funiculaire',\n",
       " \"d'1h34\",\n",
       " 'passéen',\n",
       " 'relira',\n",
       " 'Irwin',\n",
       " 'papé',\n",
       " 'malignité',\n",
       " 'sculpte',\n",
       " 'Scénario-type',\n",
       " 'tua',\n",
       " 'botruc',\n",
       " 'inopportune',\n",
       " 'Jean-Eude',\n",
       " 'présider',\n",
       " '´aime',\n",
       " 'chez-eux',\n",
       " 'poutant',\n",
       " 'pensent-ils',\n",
       " 'Pseudos-fantômes',\n",
       " 'minera',\n",
       " 'abyssales',\n",
       " 'moyen-format',\n",
       " 'Hypolithe',\n",
       " 'gif',\n",
       " 'Pffft',\n",
       " 'géo-politico-économique',\n",
       " 'surpises',\n",
       " 'pruve',\n",
       " 'Listz',\n",
       " 'maintenancier',\n",
       " 'Strings',\n",
       " 'THESEE',\n",
       " 'prépares-toi',\n",
       " 'parti.dans',\n",
       " 'scène/montage',\n",
       " 'Lantins',\n",
       " 'appercevoir',\n",
       " 'MD',\n",
       " 'giachino',\n",
       " \"scatologiques.C'est\",\n",
       " 'habille',\n",
       " \"d'hyppocrate\",\n",
       " 'infamité',\n",
       " 'Bridesmaids',\n",
       " '8.Black',\n",
       " 'urinoir',\n",
       " 'ridicle',\n",
       " 'Verneuil-Koffi',\n",
       " 'CHOI',\n",
       " 'couturier',\n",
       " 'reste',\n",
       " 'abuser',\n",
       " 'aigrelette',\n",
       " 'poulain',\n",
       " 'alunit',\n",
       " 'bouche-béé',\n",
       " 'parrêtre',\n",
       " 'brevement',\n",
       " \"l'acteur/sosie\",\n",
       " \"t'affirmes\",\n",
       " 'contre-fichions',\n",
       " 'leurss',\n",
       " 'cabotinerie',\n",
       " 'Gothiques',\n",
       " \"'Ils\",\n",
       " \"n'essoufle\",\n",
       " 'Mana',\n",
       " 'vrombissent',\n",
       " 'sacrifices…',\n",
       " \"l'attaquait\",\n",
       " 'pégre',\n",
       " 'funes-Poelvoorde',\n",
       " 'èchangiste',\n",
       " 'Burbanks',\n",
       " 'Eminem',\n",
       " 'inexsistante',\n",
       " 'roxx',\n",
       " 'non-développement',\n",
       " 'séléectionnés',\n",
       " 'invitait',\n",
       " 'rveele',\n",
       " 'ENVIRONNANT',\n",
       " 'bacl',\n",
       " 'planifient',\n",
       " 'faux.Un',\n",
       " 'joie/inquiétude',\n",
       " 'instinctivement',\n",
       " 'essoufflent',\n",
       " 'melange',\n",
       " 'Portes',\n",
       " '1x1',\n",
       " 'sexy/horreur/comédie',\n",
       " 'Brizzi…',\n",
       " 'choregraphiées',\n",
       " 'contrefaçons',\n",
       " 'impéccables',\n",
       " 'le-dit',\n",
       " 'EMMA',\n",
       " 'dèsed',\n",
       " 'hellènes',\n",
       " 'Gruner',\n",
       " \"l'agence\",\n",
       " 'enfants-après',\n",
       " 'Delacorte',\n",
       " 'my',\n",
       " 'Dépressif',\n",
       " 'precedant.En',\n",
       " 'héroïne-tornade',\n",
       " 'nul.m',\n",
       " 'dilemmes.Le',\n",
       " 'saladiers',\n",
       " \"d'authenticités\",\n",
       " 'trucs…',\n",
       " 'furniker',\n",
       " 'barricadant',\n",
       " 'qags',\n",
       " 'repartent…',\n",
       " 'Perica',\n",
       " 'frustrè',\n",
       " 'profonds.Le',\n",
       " 'RATAGE',\n",
       " 'pimentes',\n",
       " 'deconseillerais',\n",
       " 'indéfiniment',\n",
       " 'plénitudes',\n",
       " '😁',\n",
       " \"d'Otomo\",\n",
       " 'mêlès',\n",
       " 'Straithairn',\n",
       " 'Negret',\n",
       " 'cakemar',\n",
       " 'Khreiron',\n",
       " 'VOIS',\n",
       " \"l'iroquoise\",\n",
       " 'nah',\n",
       " 'Schredder',\n",
       " \"etj'ai\",\n",
       " 'décrouvrir',\n",
       " \"d'exterieurs\",\n",
       " '4½',\n",
       " 'bancaux',\n",
       " 'Pleger',\n",
       " 'isolé',\n",
       " 'lumpen-prolétariat',\n",
       " 'ComicBook',\n",
       " 'peinturée',\n",
       " \"l'anté-Amérique\",\n",
       " 'synaptique',\n",
       " 'terra-formage',\n",
       " 'poindre',\n",
       " 'Setewart',\n",
       " 'Laskas',\n",
       " 'tacodile',\n",
       " 'Youpiii',\n",
       " 'BOYHOOD',\n",
       " 'Prisonnier',\n",
       " 'wouahah',\n",
       " 'elargir',\n",
       " 'exaspérer',\n",
       " 'drôle.Tensions',\n",
       " 'agençant',\n",
       " 'Bergolio',\n",
       " 'jen',\n",
       " 'recueillement',\n",
       " 'al-Qaida',\n",
       " 'infernal',\n",
       " 'ruminé',\n",
       " 'quasi-voyeuristique',\n",
       " 'livent',\n",
       " 'Abdelaziz',\n",
       " 'représentantes',\n",
       " 'Adrien/Frantz',\n",
       " 'typology',\n",
       " 'volé',\n",
       " 'prédictive',\n",
       " 'effiacec',\n",
       " 'acceptent-ils',\n",
       " 'Liberta',\n",
       " 'attaqueraient',\n",
       " 'Yordannof',\n",
       " 'brayant',\n",
       " 'entourèe',\n",
       " 'menaçant',\n",
       " 'térasser',\n",
       " 'MERITAIT',\n",
       " 'Brodie-Sangster',\n",
       " 'Hasard',\n",
       " 'disettes',\n",
       " 'électroacoustique',\n",
       " 'coooooooooooooooooooooooooooooooooooooooool',\n",
       " 'remplissage',\n",
       " 'èmotif',\n",
       " 'stagnera',\n",
       " 'sororale',\n",
       " 'paralysés',\n",
       " \"d'homme-machine\",\n",
       " 'rallumer',\n",
       " 'Bendaoud',\n",
       " 'Rostovsky',\n",
       " 'Ferrell-Wahlberg',\n",
       " \"L'Avare\",\n",
       " 'auto-critiques',\n",
       " \"s'entassaient\",\n",
       " 'bataillenne',\n",
       " \"d'actions/baston\",\n",
       " 'François.On',\n",
       " 'soft-ultra-violente',\n",
       " 'sociétale',\n",
       " 'rebu',\n",
       " 'maisi',\n",
       " 'impressionants.Bref',\n",
       " 'aniara',\n",
       " 'super-téléphonés',\n",
       " 'eduque',\n",
       " 'Pittsburg',\n",
       " 'siècle/monde',\n",
       " 'Henri/Erica',\n",
       " 'pied😡',\n",
       " 'cousue',\n",
       " 'offert',\n",
       " 'demie-finale',\n",
       " 'duo.Laurent',\n",
       " \"d'amuse\",\n",
       " 'suite.Rien',\n",
       " 'saute-moutons',\n",
       " \"'epouvante/\",\n",
       " 'ahgreablke',\n",
       " 'St-Laurent',\n",
       " \"l'Uchronie\",\n",
       " 'soundesign',\n",
       " 'concaincants',\n",
       " 'Zanghief',\n",
       " 'Flag',\n",
       " 'pas.a',\n",
       " \"moyennes.HEADL'idée\",\n",
       " 'bleutés',\n",
       " 'superpose',\n",
       " \"n'affolera\",\n",
       " 'campaign',\n",
       " \"s'accèlere\",\n",
       " 'victoir',\n",
       " 'Expression',\n",
       " 'lucky',\n",
       " 'tombaient',\n",
       " 'québéquitude',\n",
       " 'RIDLEY',\n",
       " 'baert',\n",
       " \"s'auto-engendre\",\n",
       " 'enchaînément',\n",
       " 'filiale',\n",
       " 'detesterez',\n",
       " 'allument',\n",
       " 'Q-Bert…',\n",
       " 'Pouaaaah',\n",
       " 'teaces',\n",
       " 'vendre',\n",
       " 'familales/enfants',\n",
       " 'cambrioleurs',\n",
       " 'ð\\x9f\\x98\\x9c',\n",
       " 'battisse',\n",
       " 'révoltent',\n",
       " 'parlottent',\n",
       " 'mètier',\n",
       " 'JAUNE',\n",
       " 'pseudo-biblique',\n",
       " \"d'1h21\",\n",
       " 'fardés',\n",
       " 'Gauther',\n",
       " \"d'Aiga\",\n",
       " 'catharsis…',\n",
       " 'ANEMONE',\n",
       " 'blafarde',\n",
       " 'Tightrope',\n",
       " \"d'ammoniac\",\n",
       " 'feige',\n",
       " 'désapent',\n",
       " 'Toubon',\n",
       " 'Balibar',\n",
       " 'invalide',\n",
       " 'cabotinage',\n",
       " 'deus-Ex',\n",
       " 'amiraux',\n",
       " 'dînant',\n",
       " \"puisqu'aucune\",\n",
       " 'culturels…on',\n",
       " 'mystification',\n",
       " 'jakhe',\n",
       " 'apparaissaient',\n",
       " 'prodiges',\n",
       " \"d'inspecteur-tueur\",\n",
       " 'indecentes',\n",
       " 'aparaît',\n",
       " 'au-dedans',\n",
       " 'trepassa',\n",
       " 'carcéral.La',\n",
       " 'comptemporain',\n",
       " 'partie/heure',\n",
       " 'proprette',\n",
       " 'préférable…',\n",
       " 'interpration',\n",
       " \"L'ouverture\",\n",
       " 'tireurs',\n",
       " 'LIBERTINE',\n",
       " 'Donc…',\n",
       " 'fer/',\n",
       " 'Addictif',\n",
       " 'cascadeur/braqueur',\n",
       " 'Prevot',\n",
       " 'Boukoff',\n",
       " 'divertissante',\n",
       " 'Samosate',\n",
       " 'renfermé-resorti-rechauffé',\n",
       " 'flo',\n",
       " 'salariaux',\n",
       " 'hérisseront',\n",
       " 'manières…',\n",
       " 'Kuzama',\n",
       " 'restais',\n",
       " 'incapacité/non',\n",
       " 'Jordi',\n",
       " 'juStement',\n",
       " \"l'accordé\",\n",
       " 'blufffante',\n",
       " 'scripturaires',\n",
       " 'étiquète',\n",
       " 'pendan',\n",
       " 'rytmė',\n",
       " 'oscarifié',\n",
       " 'ambivalent',\n",
       " 'Wingo',\n",
       " 'Migraine',\n",
       " 'Mazinger',\n",
       " 'terminaux',\n",
       " 'Gaming',\n",
       " 'supportez',\n",
       " 'eifira',\n",
       " 'livre-photos',\n",
       " 'p=41105',\n",
       " 'cliarement',\n",
       " 'BatmanVSuperman',\n",
       " 'malmenez',\n",
       " 'stack',\n",
       " '2.9',\n",
       " 'malheuresment',\n",
       " 'Kanal',\n",
       " '72mm',\n",
       " 'déçue.Je',\n",
       " 'mère/veuve',\n",
       " \"l'Eliot\",\n",
       " 'personalite',\n",
       " 'europe1',\n",
       " 'kiffants',\n",
       " 'institution-là',\n",
       " \"d'Eloise\",\n",
       " \"l'expérience-film\",\n",
       " 'BRADOCK',\n",
       " 'téléportations',\n",
       " 'rétroviseurs',\n",
       " 'Binta',\n",
       " 'multi-linear',\n",
       " 'sectarisations',\n",
       " 'prennai',\n",
       " \"l'ègèrie\",\n",
       " 'attrapés',\n",
       " 'chocolatière',\n",
       " 'repetitifs.mais',\n",
       " 'sosie.',\n",
       " 'confime/nous',\n",
       " 'bondesques',\n",
       " 'Dutfield',\n",
       " 'dévouait',\n",
       " \"l'auto-analyse\",\n",
       " 'rendrez-vous.Percutant',\n",
       " \"qu'accrocheur\",\n",
       " 'pro-Dieu',\n",
       " 'sur-maitrisée',\n",
       " 'DeHaan',\n",
       " 'mC3C3AAAAme',\n",
       " 'éclairage',\n",
       " 'MOLLY',\n",
       " 'entonnées',\n",
       " \"m'intriguait\",\n",
       " 'ropres',\n",
       " 'entamant',\n",
       " 'pro-Républicains',\n",
       " 'naristique',\n",
       " 'MONTH',\n",
       " 'Ilsand',\n",
       " 'serbian',\n",
       " 'jump-care',\n",
       " 'cinématographique.Et',\n",
       " 'Rémie',\n",
       " 'Notre-Dame-de-Paris',\n",
       " 'siroterai',\n",
       " 'Trance-spotting',\n",
       " 'témoignants',\n",
       " 'técérath',\n",
       " \"l'Estérel\",\n",
       " 'détectives',\n",
       " 'Dwalin.Sans',\n",
       " 'arrière-pensé',\n",
       " 'Arzeneder',\n",
       " 'areu',\n",
       " 'Bigfoot',\n",
       " 'réquisitionnés',\n",
       " 'jeunot',\n",
       " 'cbose',\n",
       " 'Marivaux…et',\n",
       " 'diversifiés',\n",
       " \"d'Osborn\",\n",
       " 'Confite',\n",
       " 'Siman',\n",
       " 'soixante-quatre',\n",
       " 'confiserie',\n",
       " 'scharzy',\n",
       " 'THERON',\n",
       " 'soncérité',\n",
       " \"film.C'est\",\n",
       " \"l'orchidée\",\n",
       " 'nous-mêmes.Pour',\n",
       " 'Marineland',\n",
       " 'intriquée',\n",
       " 'coproduction',\n",
       " 'Nidavellir',\n",
       " 'collaborant',\n",
       " 'sans-être',\n",
       " 'salade',\n",
       " 'J§',\n",
       " 'potier',\n",
       " 'jolliiiie',\n",
       " 'raconter…Entre',\n",
       " \"qu'Atiq\",\n",
       " 'elle-même.Ne',\n",
       " 'Samie',\n",
       " \"m'intéressaient\",\n",
       " 'Marv',\n",
       " 'Niesson',\n",
       " 'génération.A',\n",
       " 'caméra-transe',\n",
       " 'bobocratie-parisiano-critique',\n",
       " 'célèste',\n",
       " 'Phrase',\n",
       " 'collocataires',\n",
       " 'Dam',\n",
       " 'Christia',\n",
       " 'beautyful',\n",
       " 'déchiqueteuse',\n",
       " 'senblables',\n",
       " 'Weller',\n",
       " 'caméra…peu',\n",
       " 'mi-Psychologique',\n",
       " 'néfaste.Marie',\n",
       " 'suicidèrent',\n",
       " '1,39',\n",
       " 'demeurent',\n",
       " 'Ennasr',\n",
       " 'scriptée',\n",
       " 'moderne.Superbe',\n",
       " 'stukas',\n",
       " 'injonctions',\n",
       " 'sUiccès',\n",
       " 'solo.Quant',\n",
       " 'PLutot',\n",
       " 'Hallal',\n",
       " 'perçois',\n",
       " 'militaro-pharmaceutique',\n",
       " 'miss-météo',\n",
       " 'Kriste',\n",
       " 'films/saga',\n",
       " 'Tegel',\n",
       " 'TOp',\n",
       " 'coup.Quel',\n",
       " 'phallo',\n",
       " '-exceptionnel',\n",
       " 'deviennent-ils',\n",
       " 'tetrouve',\n",
       " 'Multipliant',\n",
       " 'complété',\n",
       " 'bachote',\n",
       " 'dumber',\n",
       " 'Grignotez',\n",
       " 'LOURDEUR',\n",
       " 'Archinul',\n",
       " '=sa',\n",
       " 'glorification',\n",
       " 'rebutée',\n",
       " \"l'éblouissement\",\n",
       " 'bonniche',\n",
       " \"d'arnaque.la\",\n",
       " \"L'enigme\",\n",
       " 'specificté',\n",
       " 'huniers',\n",
       " '2012-d�but',\n",
       " 'noement',\n",
       " \"qu'Oliver\",\n",
       " 'beaucoup.courrez-y',\n",
       " 'couapbles',\n",
       " 'Capoeira',\n",
       " 'Blanc-Bonnet',\n",
       " 'CCS',\n",
       " 'montagne/montagne',\n",
       " 'mi-poétique',\n",
       " 'bourn',\n",
       " 'gentirobot',\n",
       " 'visuellement.Parfois',\n",
       " 'Hopkis',\n",
       " 'Denarnaud',\n",
       " 'manquiez',\n",
       " 'Woodley',\n",
       " 'renseignés',\n",
       " \"l'héroïne/\",\n",
       " 'KURYLENKO',\n",
       " '.plus',\n",
       " 'Hétérosexuelle',\n",
       " 'happend',\n",
       " 'canapè',\n",
       " 'réformés',\n",
       " 'souffreteux',\n",
       " 'Divergents…et',\n",
       " 'Domingas',\n",
       " 'forceps',\n",
       " 'Reyjavik',\n",
       " 'embarquee',\n",
       " \"l'bris\",\n",
       " '2014-',\n",
       " \"L'OMBRE\",\n",
       " 'allitérations',\n",
       " \"l'apréçier\",\n",
       " 'photojournalistes',\n",
       " 'Robbins/Eddie',\n",
       " 'passât',\n",
       " 'acolytes/potes',\n",
       " 'paraîtres',\n",
       " 'dèpend',\n",
       " 'amoncellent',\n",
       " 'freefight',\n",
       " 'Bate',\n",
       " 'Chanwook',\n",
       " 'pupilles',\n",
       " 'milice',\n",
       " 'atlante',\n",
       " 'personnalité',\n",
       " 'disparaissant',\n",
       " 'décourager',\n",
       " 'revendicatif',\n",
       " 'scénographiant',\n",
       " 'emploi.Film',\n",
       " 'rencarder',\n",
       " 'ganter',\n",
       " 'midway',\n",
       " 'semi-drame',\n",
       " \"s'affranchissant\",\n",
       " 'disparaitre.De',\n",
       " 'linguistiques',\n",
       " 'ZiYi',\n",
       " 'Lâ',\n",
       " 'Shazhana',\n",
       " 'charognes',\n",
       " \"L'importance\",\n",
       " 'BlackWidow',\n",
       " 'Caluire',\n",
       " 'CHRISTOF',\n",
       " 'apesante',\n",
       " 'genre.Pour',\n",
       " 'discernée',\n",
       " 'réintérpretter',\n",
       " 'bachelier',\n",
       " 'redire…',\n",
       " 'Donnellan/Nick',\n",
       " 'Marijuana',\n",
       " 'pourraient-il',\n",
       " 'profondeur.Où',\n",
       " \"s'épure\",\n",
       " 's´il',\n",
       " 'Stranley',\n",
       " 'Mud…',\n",
       " 'Fer-blanc',\n",
       " 'dispraît',\n",
       " 'Plante',\n",
       " 'reconquerit',\n",
       " 'Isabela',\n",
       " 'noireaude',\n",
       " 'PANINI',\n",
       " 'piège-là',\n",
       " 'provo',\n",
       " 'ennormement',\n",
       " 'NOUVEAUTÉ',\n",
       " 'reverance',\n",
       " 'redescendra',\n",
       " 'chaos.Je',\n",
       " 'Gadd',\n",
       " 'papotages',\n",
       " 'Amitiès',\n",
       " 'Footloose',\n",
       " 'Mikkelsen…efficace',\n",
       " 'espionnage-passion',\n",
       " 'honte.Franchement',\n",
       " 'Craquements',\n",
       " 'enfilocher',\n",
       " \"d'insaisissables\",\n",
       " 'Lelouch/Dujardin',\n",
       " 'anti-dopage',\n",
       " 'Ejifor',\n",
       " 'film.Comme',\n",
       " 'arrive.La',\n",
       " \"qu'intensément\",\n",
       " 'Fugges',\n",
       " 'premier/s',\n",
       " \"J'attend\",\n",
       " 'DEMAAAAGOOOGIIIIIIE',\n",
       " 'cuiné',\n",
       " \"J'enlève\",\n",
       " 'néogothique',\n",
       " 'shoot',\n",
       " 'circonscrite',\n",
       " \"d'Élodie\",\n",
       " 'decidément',\n",
       " 'restiant',\n",
       " \"'Lascia\",\n",
       " 'NSTB',\n",
       " 'géopolisation',\n",
       " 'film…grand',\n",
       " 'bêtises.Ca',\n",
       " 'définies',\n",
       " '.saga',\n",
       " 'aveu',\n",
       " 'convictions/en',\n",
       " \"d'inhabituel\",\n",
       " 'décidait',\n",
       " 'Found-Footage',\n",
       " 'Blackbriar',\n",
       " 'cinéma-là',\n",
       " \"qu'in\",\n",
       " 'Donnant',\n",
       " 'séparatiste',\n",
       " 'flouées',\n",
       " 'Fitness',\n",
       " 'Inutile.1h40',\n",
       " 'bol',\n",
       " 'superficielel',\n",
       " 'Beausejour',\n",
       " 'désespèreraient',\n",
       " 'russes…',\n",
       " 'propoe',\n",
       " ',je',\n",
       " 'coordinateurs',\n",
       " 'Panamera',\n",
       " 'vandecamp',\n",
       " 'sérieuse',\n",
       " 'situations-gagues',\n",
       " \"j'vai\",\n",
       " 'bissextiles',\n",
       " 'fellationnaire',\n",
       " 'claustrogène',\n",
       " 'laique',\n",
       " 'Tf1',\n",
       " 'Felipe',\n",
       " 'visonnage',\n",
       " 'précéda',\n",
       " 'rgand',\n",
       " 'désolés',\n",
       " 'saille',\n",
       " 'Waren',\n",
       " \"qu'apprendre\",\n",
       " \"L'objet\",\n",
       " 'catastrophait',\n",
       " \"d'agissement\",\n",
       " 'obcures',\n",
       " '17h30',\n",
       " 'A.Dupontel-acteur',\n",
       " 'hommes-framboises',\n",
       " 'Enchainé',\n",
       " '100mins',\n",
       " 'furibarde',\n",
       " \"d'Egypte\",\n",
       " 'non-enfant',\n",
       " 'bouger',\n",
       " 'sonnerait-elle',\n",
       " \"d'escarmouches\",\n",
       " \"d'Herzog\",\n",
       " 'toilettés',\n",
       " 'hyper-référencée',\n",
       " 'remix',\n",
       " \"n'interviennent\",\n",
       " 'commensurable',\n",
       " 'animalisation',\n",
       " \"s'etreignent\",\n",
       " 'Farr',\n",
       " 'cicatrises',\n",
       " 'boules-quies',\n",
       " 'bosser',\n",
       " 'claqué',\n",
       " 'pompeur',\n",
       " \"l'éblouissante\",\n",
       " \"'n'est\",\n",
       " 'caractérose',\n",
       " 'db',\n",
       " 'PIF',\n",
       " 'spacieuse',\n",
       " 'pseudos-héros-bobos',\n",
       " 'inspiree',\n",
       " '//lackingfeather.blogspot.com/2010/11/critique-unstoppable.html',\n",
       " 'Beaux-',\n",
       " 'invétéré',\n",
       " 'Maureau',\n",
       " 'bonhomme-ventouse',\n",
       " 'hâtez',\n",
       " 'Lorenzo',\n",
       " 'mini-van',\n",
       " 'Lost-',\n",
       " 'archétypale',\n",
       " \"l'arigo\",\n",
       " 'ratonnades',\n",
       " 'fin.La',\n",
       " 'Considèrè',\n",
       " 'prévenants',\n",
       " 'lézards/humains',\n",
       " 'frémissant',\n",
       " 'Mmddrr',\n",
       " 'acteur/agent',\n",
       " 'hélant',\n",
       " 'réaliser.Si',\n",
       " 'plantueuse',\n",
       " 'annihilée',\n",
       " 'passiant.je',\n",
       " 'Dixon…',\n",
       " 'mettrais-je',\n",
       " \"d'allumage\",\n",
       " 'Shimosawa',\n",
       " 'créature=espoir',\n",
       " 'Walter/Sean',\n",
       " 're-mobilisation',\n",
       " \"beau.J'avais\",\n",
       " \"chez-d'œuvre\",\n",
       " \"n'amorce\",\n",
       " 'derniervolet',\n",
       " 'physiquement',\n",
       " 'enmenné',\n",
       " 'amphéts',\n",
       " 'élémentaire',\n",
       " 'amis/boulot',\n",
       " 'diagonal',\n",
       " 'comence',\n",
       " 'laisser-pour-compte',\n",
       " 'jeunes-vieux',\n",
       " 'peletée',\n",
       " 'interMinables',\n",
       " 'transfrontières',\n",
       " 'Joon',\n",
       " 'CO2',\n",
       " 'découvertes…',\n",
       " 'rôtis',\n",
       " 'LOOOOOL',\n",
       " 'combis',\n",
       " 'apurés',\n",
       " 'personnages-clefs',\n",
       " 'solidaire/communautaire',\n",
       " 'FILMSANCTU',\n",
       " 'suite.Globalement',\n",
       " \"'Feel\",\n",
       " 'Maigrelette',\n",
       " 'gousse',\n",
       " 'bâillonne',\n",
       " 'Cheshire',\n",
       " 'Kodomo',\n",
       " 'Davies',\n",
       " 'abstenais',\n",
       " 'bacleé',\n",
       " 'TRIERS',\n",
       " '616',\n",
       " 'Avia',\n",
       " 'exiter',\n",
       " 'Requa',\n",
       " 'inférieure',\n",
       " 'prétend',\n",
       " 'archet',\n",
       " 'D17',\n",
       " 'pauvres.Le',\n",
       " 'précepteur',\n",
       " 'Brolin-Clooney',\n",
       " 'BPI',\n",
       " \"l'indigestion.Certes\",\n",
       " 'simplicité….Autant',\n",
       " 'telephonne',\n",
       " 'Peña',\n",
       " \"m'étalerai\",\n",
       " 'reenforce',\n",
       " 'surprotectrice',\n",
       " 'ANNABELLA',\n",
       " 'Rhinoplastie',\n",
       " \"d'anneries\",\n",
       " 'viencent',\n",
       " 'pseudo-cynisme',\n",
       " 'concede',\n",
       " 'Minecraft',\n",
       " 'fordiens',\n",
       " \"s'allonger\",\n",
       " 'ingénument',\n",
       " 'bidonnées',\n",
       " 'déplacaient',\n",
       " 'patritotes',\n",
       " 'impotente',\n",
       " 'intéressant',\n",
       " 'néoclassique',\n",
       " 'StarLords',\n",
       " 'Poublots',\n",
       " 'Hellblazer',\n",
       " 'épanouiront',\n",
       " \"n'accompagnera\",\n",
       " 'barbarian',\n",
       " 'rapetisse-le',\n",
       " 'soustraction',\n",
       " 'Kirito',\n",
       " 'request',\n",
       " 'fossilisation',\n",
       " 'super-coke',\n",
       " 'première…',\n",
       " \"l'hypnagogie\",\n",
       " 'Bitzer',\n",
       " 'câchée',\n",
       " 'engagé…aucune',\n",
       " \"n'ennuyer\",\n",
       " 'cruels….Ces',\n",
       " 'intéréssés',\n",
       " 'HEADQuant',\n",
       " 'pressurés',\n",
       " \"L'asservissement\",\n",
       " 'dC3C3A9A9jouer',\n",
       " 'Super-Nintendo',\n",
       " 'Graig',\n",
       " ...]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexique_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb246e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "import numpy as np\n",
    "\n",
    "def matrice(message, lexique_unique):\n",
    "    h = table_h(lexique_unique)\n",
    "    nombre_lignes = message.shape[0]\n",
    "    nombre_colones = len(h)\n",
    "    \n",
    "    # Utilisation d'une matrice creuse\n",
    "    m = lil_matrix((nombre_lignes, nombre_colones), dtype=np.float32)\n",
    "\n",
    "    for i in range(nombre_lignes):\n",
    "        for mot in lexique_unique:\n",
    "            if mot in message[i]:  # Seulement traiter si le mot est dans le message\n",
    "                j = h[mot]\n",
    "                mot += \" \"\n",
    "                nombre_occurence = message[i].count(mot)\n",
    "                m[i, j] = nombre_occurence\n",
    "\n",
    "    print(\"fin de la foncrion\\n\") \n",
    "    return m.tocsr()  # Convertir en format CSR pour une meilleure efficacité\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5dd3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creaton de la matrice\n",
    "#donnees_train= matrice(message_train,lexique_unique)\n",
    "#donnees_test= matrice(message_test,lexique_unique)\n",
    "donnees_dev= matrice(message_dev,lexique_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5130d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees_train= matrice(message_train,lexique_unique)\n",
    "donnees_test= matrice(message_test,lexique_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe2aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format accepter par svm\n",
    "svm_train = convertir_svm(donnees_train , label_train )\n",
    "svm_test = convertir_svm(donnees_test , label_test )\n",
    "svm_dev = convertir_svm(donnees_dev , label_dev )\n",
    "\n",
    "#ecrire dans le fichier\n",
    "file(\"train.svm\",svm_train)\n",
    "file(\"test.svm\",svm_test)\n",
    "file(\"dev.svm\",svm_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d988a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
