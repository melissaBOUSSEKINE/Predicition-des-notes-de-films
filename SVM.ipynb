{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f11bca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import operator as op\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9ba07b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement des donnes \n",
    "liste_id = []\n",
    "liste_label = []\n",
    "liste_message = []\n",
    "file_train = 'data/train.xml'\n",
    "file_dev   = 'data/dev.xml'\n",
    "file_test  = 'data/test.xml' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f0de961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml_to_dataframe(file_path):\n",
    "    # Analyse du fichier XML\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Cr√©ation d'une liste vide pour stocker les donn√©es\n",
    "    data = []\n",
    "\n",
    "    # Parcours des √©l√©ments de commentaire\n",
    "    for comment in root.findall('comment'):\n",
    "        movie = comment.find('movie').text\n",
    "        review_id = comment.find('review_id').text\n",
    "        name = comment.find('name').text\n",
    "        user_id = comment.find('user_id').text\n",
    "        note = comment.find('note').text.replace(',', '.')\n",
    "        commentaire = comment.find('commentaire').text\n",
    "\n",
    "        # Ajout des donn√©es dans la liste sous forme de dictionnaire\n",
    "        data.append({\n",
    "            'movie': movie,\n",
    "            'review_id': review_id,\n",
    "            'name': name,\n",
    "            'user_id': user_id,\n",
    "            'note': note,\n",
    "            'commentaire': commentaire\n",
    "        })\n",
    "\n",
    "    # Cr√©ation d'un DataFrame \n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03fff348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction pour le fichier de test \n",
    "def read_xml_to_dataframeTest(file_path):\n",
    "    # Analyse du fichier XML\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Cr√©ation d'une liste vide pour stocker les donn√©es\n",
    "    data = []\n",
    "\n",
    "    # Parcours des √©l√©ments de commentaire\n",
    "    for comment in root.findall('comment'):\n",
    "        # Initialisation d'un dictionnaire pour chaque commentaire\n",
    "        comment_data = {}\n",
    "\n",
    "        # Extraction de chaque √©l√©ment si disponible et ajout au dictionnaire\n",
    "        movie = comment.find('movie')\n",
    "        if movie is not None:\n",
    "            comment_data['movie'] = movie.text\n",
    "\n",
    "        review_id = comment.find('review_id')\n",
    "        if review_id is not None:\n",
    "            comment_data['review_id'] = review_id.text\n",
    "\n",
    "        name = comment.find('name')\n",
    "        if name is not None:\n",
    "            comment_data['name'] = name.text\n",
    "\n",
    "        user_id = comment.find('user_id')\n",
    "        if user_id is not None:\n",
    "            comment_data['user_id'] = user_id.text\n",
    "\n",
    "        # Note is not present in the given data, but if it's sometimes included,\n",
    "        # you can check for it like this:\n",
    "        note = comment.find('note')\n",
    "        if note is not None:\n",
    "            comment_data['note'] = note.text.replace(',', '.')\n",
    "\n",
    "        commentaire = comment.find('commentaire')\n",
    "        if commentaire is not None:\n",
    "            comment_data['commentaire'] = commentaire.text\n",
    "\n",
    "        # Ajout des donn√©es dans la liste sous forme de dictionnaire\n",
    "        data.append(comment_data)\n",
    "\n",
    "    # Cr√©ation d'un DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3d295",
   "metadata": {},
   "source": [
    "# R√©cup√©ration des donn√©es dans des dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f453b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cr√©ation DataFrame\n",
    "data_dev   = read_xml_to_dataframe(file_dev)\n",
    "data_train = read_xml_to_dataframe(file_train)\n",
    "data_test  = read_xml_to_dataframeTest(file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23098bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\"creation de lexique###############\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lexique_(message):\n",
    "    lexique =[]\n",
    "    lexique_unique = []\n",
    "    for m in range(len(message)):\n",
    "        liste = nltk.word_tokenize(message[m],language=\"french\")   \n",
    "        for  i in liste:\n",
    "            lexique.append(lemmatizer.lemmatize(i))\n",
    "        #####lexique unique###\n",
    "    for i in range(len(lexique)):\n",
    "        if lexique[i] not in lexique_unique :\n",
    "            lexique_unique.append(lexique[i])\n",
    "    return lexique_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf5629a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################Table de H################\n",
    "def table_h(lexique_unique):\n",
    "    h = {}\n",
    "    i = 0\n",
    "    for mot in lexique_unique:\n",
    "       h[mot] = i\n",
    "       i+=1\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6afc3085",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################Matrice#######################\n",
    "def matrice(message,lexique_unique):\n",
    "    h = table_h(lexique_unique)\n",
    "    nombre_lignes = message.shape[0]\n",
    "    nombre_colones = len(h)\n",
    "    m = np.zeros((nombre_lignes,nombre_colones))\n",
    "    \n",
    "    for i in range(nombre_lignes):\n",
    "       #print(\"i\",i)\n",
    "        for mot in lexique_unique:\n",
    "            j = h[mot]\n",
    "            #nombre d'occurence de mot dans message [i]\n",
    "            mot = mot+\" \"\n",
    "            nombre_occurence =  message[i].count(mot)\n",
    "            m[i,j] =  nombre_occurence\n",
    "              \n",
    "    print(\"fin de la foncrion\\n\") \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48127398",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################SVM############################\n",
    "def convertir_svm(matrice, etiquettes):\n",
    "    # Initialisation de la cha√Æne de caract√®res qui contiendra le fichier SVM\n",
    "    svm = \"\"\n",
    "\n",
    "    # Parcourt de la matrice de donn√©es \n",
    "    for i in range(matrice.shape[0]):\n",
    "        # Ajout de l'√©tiquette de la classe en d√©but de ligne\n",
    "        svm += str(etiquettes[i]) + \" \"\n",
    "        # Parcourt de chaque colonne de la ligne courante\n",
    "        for j in range(matrice.shape[1]):\n",
    "            # Si la valeur de la caract√©ristique est non nulle\n",
    "            if matrice[i, j] != 0:\n",
    "                svm += f\"{j+1}:{matrice[i, j]} \"\n",
    "        # Ajout du retour √† la ligne √† la fin de la ligne courante\n",
    "        svm += \"\\n\"\n",
    "    \n",
    "    return svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68cd4640",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "def file(nom,contenu):\n",
    "    \n",
    "    # Ouvrez le fichier en mode √©criture\n",
    "    with io.open(nom, \"w\", encoding=\"utf-8\") as f:\n",
    "        # √âcrivez vos lignes de string dans le fichier\n",
    "        f.writelines(contenu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbd56270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r√©cup√©ration des commentaire\n",
    "message_test = np.array(data_test['commentaire'])\n",
    "message_dev = np.array(data_dev['commentaire'])\n",
    "message_train = np.array(data_train['commentaire'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8582897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\etudiant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def lexique_(messages):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lexique = set()\n",
    "\n",
    "    for message in messages:\n",
    "        if message is not None:  # V√©rifiez que le message n'est pas None\n",
    "            tokens = word_tokenize(message, language=\"french\")\n",
    "            for token in tokens:\n",
    "                lexique.add(lemmatizer.lemmatize(token))\n",
    "\n",
    "    return list(lexique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d51b7ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation de lexique\n",
    "lexique_unique = lexique_(message_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e75abc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['traduisit',\n",
       " 'Pic',\n",
       " 'mono-parentales',\n",
       " \"s'accomplit\",\n",
       " 'incontestable‚Ä¶',\n",
       " 'percev√©rance',\n",
       " \"L'aversion\",\n",
       " 'Moriarty-Cassady',\n",
       " 'moyen.Selon',\n",
       " 'p√¢lira',\n",
       " 'Ensuite',\n",
       " 'quelques',\n",
       " \"l'arrangera\",\n",
       " 'France.Sinc√®rement',\n",
       " 'acupuncteur',\n",
       " 'klapishiens',\n",
       " 'NewYork',\n",
       " 'hyper-satur√©es',\n",
       " 'aneaux',\n",
       " 'd√©valiser',\n",
       " 'Latinos',\n",
       " 'winstherpoon',\n",
       " 'n√®gociateur',\n",
       " 'cornichonnerie',\n",
       " 'form√®rent',\n",
       " 'Matriochka',\n",
       " 'fatigu√©s',\n",
       " 'Assassinats',\n",
       " 'po√©tis√©e',\n",
       " 'Jaques-Yves',\n",
       " 'trouvables',\n",
       " 'Dawe',\n",
       " 'Stapple',\n",
       " 'machin√©en',\n",
       " 'am√©n√©es',\n",
       " 'ni-plus',\n",
       " 'reboots/remakes/spin-offs',\n",
       " 'tortueuse',\n",
       " 'Schwarziennes',\n",
       " 'sur-dos√©es',\n",
       " 'grimait',\n",
       " '√âvitable',\n",
       " 'blockbuster^^',\n",
       " '//www.cineserie.com/dossiers/gros-plan/gros-plan-john-wick-retour-sur-une-des-meilleures-sagas-daction-contemporaines-2549560/',\n",
       " 'rembourrage',\n",
       " \"L'escalavage\",\n",
       " 'offrirai',\n",
       " 'effectu√©s',\n",
       " 'blondeur',\n",
       " 'emennant',\n",
       " 'zappette',\n",
       " 'protectrices',\n",
       " 'menace‚Ä¶',\n",
       " 'bisexuelle',\n",
       " 'satiriser',\n",
       " 'polygamie',\n",
       " 'Retro',\n",
       " 'blafarde.Pas',\n",
       " 'Alexsandr',\n",
       " 'maxamovies',\n",
       " '8-o',\n",
       " 'comedie/action/nanard',\n",
       " 'arrosement',\n",
       " '//www.facebook.com/critiquedefilmsdhorreur/',\n",
       " \"quarts-d'heure\",\n",
       " 'vieillissons',\n",
       " 'cart√©sianisme',\n",
       " 'r√™vassant',\n",
       " \"'Us\",\n",
       " \"comprend.D'ailleurs\",\n",
       " 'ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩü§óÔøΩ',\n",
       " 'admiarablement',\n",
       " \"s'appartient\",\n",
       " 'intr√™t',\n",
       " '√©fets',\n",
       " \"l'invocation\",\n",
       " 'bleffant',\n",
       " \"dramatique.L'impression\",\n",
       " 'PEYRAC',\n",
       " 'sagira',\n",
       " \"d'hominid√©s\",\n",
       " 'encaiss√©es',\n",
       " 'S.Az√©ma',\n",
       " \"s'√©crivent\",\n",
       " '//clairedanslessallesobscures.over-blog.com/article-la-guerre-est-declaree-84787816.html',\n",
       " 'TANG',\n",
       " 'tard.Pour',\n",
       " 'parivent',\n",
       " 'contr√¥les',\n",
       " \"presqu'irr√©aliste\",\n",
       " '√©crira-t-il',\n",
       " 'Whitworth',\n",
       " 'comen√ßait',\n",
       " '1910.',\n",
       " 'I.CARRE',\n",
       " 'Fourmidable',\n",
       " '100k',\n",
       " 'callanque',\n",
       " '√©leves',\n",
       " 'malcolm',\n",
       " 'kickboxers',\n",
       " 'pl√¢tri√®re',\n",
       " 'commun2C2C',\n",
       " 'voir^^',\n",
       " 'B.13',\n",
       " 'PATHETIQUE',\n",
       " 'r√©humanisation',\n",
       " 'allourdir',\n",
       " 'gla√ß√©s',\n",
       " 'd√©conseilleront',\n",
       " 'bestiasse',\n",
       " 'Mentionnons',\n",
       " 'd√©fouraillages',\n",
       " 'p√©troleuse',\n",
       " 'sc√®nes-√†-sursaut',\n",
       " 'r√©alisateurs/r√©alisatrices',\n",
       " 'samoa',\n",
       " 'sauter/exploser',\n",
       " 'finirons',\n",
       " 'Cailley',\n",
       " 'Snowdon',\n",
       " 'DORKEL',\n",
       " 'tagger',\n",
       " \"s'organisait\",\n",
       " '√©jac',\n",
       " \"Qu'est-ce-qui\",\n",
       " 'r√©cup√©rons',\n",
       " 'sauve-qui-peut',\n",
       " 'survitamint√©',\n",
       " 'n√©o-',\n",
       " 'Sieg',\n",
       " 'D√©faillante',\n",
       " \"Qu'aime-t-on\",\n",
       " 'tout‚Ä¶.A',\n",
       " 'gillet',\n",
       " 'Daniel/le',\n",
       " 'genrall',\n",
       " 'eXtase',\n",
       " 'incomprensibles',\n",
       " 'patou',\n",
       " 'st√©r√©oscopique',\n",
       " 'DELEVINGNE',\n",
       " 'POURRI',\n",
       " '√©chelle‚Ä¶avec',\n",
       " 'articiel',\n",
       " 'enlaidis',\n",
       " 'moiti√©/dernier',\n",
       " 'Baer/Magimel',\n",
       " 'Infid√©les',\n",
       " 'zoms',\n",
       " 'colonnade',\n",
       " 'original.Dans',\n",
       " 'Fictive-Thriller',\n",
       " 'chaste',\n",
       " 'REBECCA',\n",
       " 'Dargen',\n",
       " 'Bordage',\n",
       " 'mieux/',\n",
       " 'MIKKELSEN',\n",
       " \"d'entraineur\",\n",
       " 'thanos',\n",
       " 'quasi-mythique',\n",
       " '-2011',\n",
       " \"s'encombrer\",\n",
       " 'd√®cliner',\n",
       " 'BlackBox',\n",
       " 'Philosophiquement',\n",
       " 'Mikelsen',\n",
       " 'Spillneir',\n",
       " 'vision/adaptation',\n",
       " 'Funiculaire',\n",
       " \"d'1h34\",\n",
       " 'pass√©en',\n",
       " 'relira',\n",
       " 'Irwin',\n",
       " 'pap√©',\n",
       " 'malignit√©',\n",
       " 'sculpte',\n",
       " 'Sc√©nario-type',\n",
       " 'tua',\n",
       " 'botruc',\n",
       " 'inopportune',\n",
       " 'Jean-Eude',\n",
       " 'pr√©sider',\n",
       " '¬¥aime',\n",
       " 'chez-eux',\n",
       " 'poutant',\n",
       " 'pensent-ils',\n",
       " 'Pseudos-fant√¥mes',\n",
       " 'minera',\n",
       " 'abyssales',\n",
       " 'moyen-format',\n",
       " 'Hypolithe',\n",
       " 'gif',\n",
       " 'Pffft',\n",
       " 'g√©o-politico-√©conomique',\n",
       " 'surpises',\n",
       " 'pruve',\n",
       " 'Listz',\n",
       " 'maintenancier',\n",
       " 'Strings',\n",
       " 'THESEE',\n",
       " 'pr√©pares-toi',\n",
       " 'parti.dans',\n",
       " 'sc√®ne/montage',\n",
       " 'Lantins',\n",
       " 'appercevoir',\n",
       " 'MD',\n",
       " 'giachino',\n",
       " \"scatologiques.C'est\",\n",
       " 'habille',\n",
       " \"d'hyppocrate\",\n",
       " 'infamit√©',\n",
       " 'Bridesmaids',\n",
       " '8.Black',\n",
       " 'urinoir',\n",
       " 'ridicle',\n",
       " 'Verneuil-Koffi',\n",
       " 'CHOI',\n",
       " 'couturier',\n",
       " 'reste',\n",
       " 'abuser',\n",
       " 'aigrelette',\n",
       " 'poulain',\n",
       " 'alunit',\n",
       " 'bouche-b√©√©',\n",
       " 'parr√™tre',\n",
       " 'brevement',\n",
       " \"l'acteur/sosie\",\n",
       " \"t'affirmes\",\n",
       " 'contre-fichions',\n",
       " 'leurss',\n",
       " 'cabotinerie',\n",
       " 'Gothiques',\n",
       " \"'Ils\",\n",
       " \"n'essoufle\",\n",
       " 'Mana',\n",
       " 'vrombissent',\n",
       " 'sacrifices‚Ä¶',\n",
       " \"l'attaquait\",\n",
       " 'p√©gre',\n",
       " 'funes-Poelvoorde',\n",
       " '√®changiste',\n",
       " 'Burbanks',\n",
       " 'Eminem',\n",
       " 'inexsistante',\n",
       " 'roxx',\n",
       " 'non-d√©veloppement',\n",
       " 's√©l√©ectionn√©s',\n",
       " 'invitait',\n",
       " 'rveele',\n",
       " 'ENVIRONNANT',\n",
       " 'bacl',\n",
       " 'planifient',\n",
       " 'faux.Un',\n",
       " 'joie/inqui√©tude',\n",
       " 'instinctivement',\n",
       " 'essoufflent',\n",
       " 'melange',\n",
       " 'Portes',\n",
       " '1x1',\n",
       " 'sexy/horreur/com√©die',\n",
       " 'Brizzi‚Ä¶',\n",
       " 'choregraphi√©es',\n",
       " 'contrefa√ßons',\n",
       " 'imp√©ccables',\n",
       " 'le-dit',\n",
       " 'EMMA',\n",
       " 'd√®sed',\n",
       " 'hell√®nes',\n",
       " 'Gruner',\n",
       " \"l'agence\",\n",
       " 'enfants-apr√®s',\n",
       " 'Delacorte',\n",
       " 'my',\n",
       " 'D√©pressif',\n",
       " 'precedant.En',\n",
       " 'h√©ro√Øne-tornade',\n",
       " 'nul.m',\n",
       " 'dilemmes.Le',\n",
       " 'saladiers',\n",
       " \"d'authenticit√©s\",\n",
       " 'trucs‚Ä¶',\n",
       " 'furniker',\n",
       " 'barricadant',\n",
       " 'qags',\n",
       " 'repartent‚Ä¶',\n",
       " 'Perica',\n",
       " 'frustr√®',\n",
       " 'profonds.Le',\n",
       " 'RATAGE',\n",
       " 'pimentes',\n",
       " 'deconseillerais',\n",
       " 'ind√©finiment',\n",
       " 'pl√©nitudes',\n",
       " 'üòÅ',\n",
       " \"d'Otomo\",\n",
       " 'm√™l√®s',\n",
       " 'Straithairn',\n",
       " 'Negret',\n",
       " 'cakemar',\n",
       " 'Khreiron',\n",
       " 'VOIS',\n",
       " \"l'iroquoise\",\n",
       " 'nah',\n",
       " 'Schredder',\n",
       " \"etj'ai\",\n",
       " 'd√©crouvrir',\n",
       " \"d'exterieurs\",\n",
       " '4¬Ω',\n",
       " 'bancaux',\n",
       " 'Pleger',\n",
       " 'isol√©',\n",
       " 'lumpen-prol√©tariat',\n",
       " 'ComicBook',\n",
       " 'peintur√©e',\n",
       " \"l'ant√©-Am√©rique\",\n",
       " 'synaptique',\n",
       " 'terra-formage',\n",
       " 'poindre',\n",
       " 'Setewart',\n",
       " 'Laskas',\n",
       " 'tacodile',\n",
       " 'Youpiii',\n",
       " 'BOYHOOD',\n",
       " 'Prisonnier',\n",
       " 'wouahah',\n",
       " 'elargir',\n",
       " 'exasp√©rer',\n",
       " 'dr√¥le.Tensions',\n",
       " 'agen√ßant',\n",
       " 'Bergolio',\n",
       " 'jen',\n",
       " 'recueillement',\n",
       " 'al-Qaida',\n",
       " 'infernal',\n",
       " 'rumin√©',\n",
       " 'quasi-voyeuristique',\n",
       " 'livent',\n",
       " 'Abdelaziz',\n",
       " 'repr√©sentantes',\n",
       " 'Adrien/Frantz',\n",
       " 'typology',\n",
       " 'vol√©',\n",
       " 'pr√©dictive',\n",
       " 'effiacec',\n",
       " 'acceptent-ils',\n",
       " 'Liberta',\n",
       " 'attaqueraient',\n",
       " 'Yordannof',\n",
       " 'brayant',\n",
       " 'entour√®e',\n",
       " 'mena√ßant',\n",
       " 't√©rasser',\n",
       " 'MERITAIT',\n",
       " 'Brodie-Sangster',\n",
       " 'Hasard',\n",
       " 'disettes',\n",
       " '√©lectroacoustique',\n",
       " 'coooooooooooooooooooooooooooooooooooooooool',\n",
       " 'remplissage',\n",
       " '√®motif',\n",
       " 'stagnera',\n",
       " 'sororale',\n",
       " 'paralys√©s',\n",
       " \"d'homme-machine\",\n",
       " 'rallumer',\n",
       " 'Bendaoud',\n",
       " 'Rostovsky',\n",
       " 'Ferrell-Wahlberg',\n",
       " \"L'Avare\",\n",
       " 'auto-critiques',\n",
       " \"s'entassaient\",\n",
       " 'bataillenne',\n",
       " \"d'actions/baston\",\n",
       " 'Fran√ßois.On',\n",
       " 'soft-ultra-violente',\n",
       " 'soci√©tale',\n",
       " 'rebu',\n",
       " 'maisi',\n",
       " 'impressionants.Bref',\n",
       " 'aniara',\n",
       " 'super-t√©l√©phon√©s',\n",
       " 'eduque',\n",
       " 'Pittsburg',\n",
       " 'si√®cle/monde',\n",
       " 'Henri/Erica',\n",
       " 'piedüò°',\n",
       " 'cousue',\n",
       " 'offert',\n",
       " 'demie-finale',\n",
       " 'duo.Laurent',\n",
       " \"d'amuse\",\n",
       " 'suite.Rien',\n",
       " 'saute-moutons',\n",
       " \"'epouvante/\",\n",
       " 'ahgreablke',\n",
       " 'St-Laurent',\n",
       " \"l'Uchronie\",\n",
       " 'soundesign',\n",
       " 'concaincants',\n",
       " 'Zanghief',\n",
       " 'Flag',\n",
       " 'pas.a',\n",
       " \"moyennes.HEADL'id√©e\",\n",
       " 'bleut√©s',\n",
       " 'superpose',\n",
       " \"n'affolera\",\n",
       " 'campaign',\n",
       " \"s'acc√®lere\",\n",
       " 'victoir',\n",
       " 'Expression',\n",
       " 'lucky',\n",
       " 'tombaient',\n",
       " 'qu√©b√©quitude',\n",
       " 'RIDLEY',\n",
       " 'baert',\n",
       " \"s'auto-engendre\",\n",
       " 'encha√Æn√©ment',\n",
       " 'filiale',\n",
       " 'detesterez',\n",
       " 'allument',\n",
       " 'Q-Bert‚Ä¶',\n",
       " 'Pouaaaah',\n",
       " 'teaces',\n",
       " 'vendre',\n",
       " 'familales/enfants',\n",
       " 'cambrioleurs',\n",
       " '√∞\\x9f\\x98\\x9c',\n",
       " 'battisse',\n",
       " 'r√©voltent',\n",
       " 'parlottent',\n",
       " 'm√®tier',\n",
       " 'JAUNE',\n",
       " 'pseudo-biblique',\n",
       " \"d'1h21\",\n",
       " 'fard√©s',\n",
       " 'Gauther',\n",
       " \"d'Aiga\",\n",
       " 'catharsis‚Ä¶',\n",
       " 'ANEMONE',\n",
       " 'blafarde',\n",
       " 'Tightrope',\n",
       " \"d'ammoniac\",\n",
       " 'feige',\n",
       " 'd√©sapent',\n",
       " 'Toubon',\n",
       " 'Balibar',\n",
       " 'invalide',\n",
       " 'cabotinage',\n",
       " 'deus-Ex',\n",
       " 'amiraux',\n",
       " 'd√Ænant',\n",
       " \"puisqu'aucune\",\n",
       " 'culturels‚Ä¶on',\n",
       " 'mystification',\n",
       " 'jakhe',\n",
       " 'apparaissaient',\n",
       " 'prodiges',\n",
       " \"d'inspecteur-tueur\",\n",
       " 'indecentes',\n",
       " 'apara√Æt',\n",
       " 'au-dedans',\n",
       " 'trepassa',\n",
       " 'carc√©ral.La',\n",
       " 'comptemporain',\n",
       " 'partie/heure',\n",
       " 'proprette',\n",
       " 'pr√©f√©rable‚Ä¶',\n",
       " 'interpration',\n",
       " \"L'ouverture\",\n",
       " 'tireurs',\n",
       " 'LIBERTINE',\n",
       " 'Donc‚Ä¶',\n",
       " 'fer/',\n",
       " 'Addictif',\n",
       " 'cascadeur/braqueur',\n",
       " 'Prevot',\n",
       " 'Boukoff',\n",
       " 'divertissante',\n",
       " 'Samosate',\n",
       " 'renferm√©-resorti-rechauff√©',\n",
       " 'flo',\n",
       " 'salariaux',\n",
       " 'h√©risseront',\n",
       " 'mani√®res‚Ä¶',\n",
       " 'Kuzama',\n",
       " 'restais',\n",
       " 'incapacit√©/non',\n",
       " 'Jordi',\n",
       " 'juStement',\n",
       " \"l'accord√©\",\n",
       " 'blufffante',\n",
       " 'scripturaires',\n",
       " '√©tiqu√®te',\n",
       " 'pendan',\n",
       " 'rytmƒó',\n",
       " 'oscarifi√©',\n",
       " 'ambivalent',\n",
       " 'Wingo',\n",
       " 'Migraine',\n",
       " 'Mazinger',\n",
       " 'terminaux',\n",
       " 'Gaming',\n",
       " 'supportez',\n",
       " 'eifira',\n",
       " 'livre-photos',\n",
       " 'p=41105',\n",
       " 'cliarement',\n",
       " 'BatmanVSuperman',\n",
       " 'malmenez',\n",
       " 'stack',\n",
       " '2.9',\n",
       " 'malheuresment',\n",
       " 'Kanal',\n",
       " '72mm',\n",
       " 'd√©√ßue.Je',\n",
       " 'm√®re/veuve',\n",
       " \"l'Eliot\",\n",
       " 'personalite',\n",
       " 'europe1',\n",
       " 'kiffants',\n",
       " 'institution-l√†',\n",
       " \"d'Eloise\",\n",
       " \"l'exp√©rience-film\",\n",
       " 'BRADOCK',\n",
       " 't√©l√©portations',\n",
       " 'r√©troviseurs',\n",
       " 'Binta',\n",
       " 'multi-linear',\n",
       " 'sectarisations',\n",
       " 'prennai',\n",
       " \"l'√®g√®rie\",\n",
       " 'attrap√©s',\n",
       " 'chocolati√®re',\n",
       " 'repetitifs.mais',\n",
       " 'sosie.',\n",
       " 'confime/nous',\n",
       " 'bondesques',\n",
       " 'Dutfield',\n",
       " 'd√©vouait',\n",
       " \"l'auto-analyse\",\n",
       " 'rendrez-vous.Percutant',\n",
       " \"qu'accrocheur\",\n",
       " 'pro-Dieu',\n",
       " 'sur-maitris√©e',\n",
       " 'DeHaan',\n",
       " 'mC3C3AAAAme',\n",
       " '√©clairage',\n",
       " 'MOLLY',\n",
       " 'entonn√©es',\n",
       " \"m'intriguait\",\n",
       " 'ropres',\n",
       " 'entamant',\n",
       " 'pro-R√©publicains',\n",
       " 'naristique',\n",
       " 'MONTH',\n",
       " 'Ilsand',\n",
       " 'serbian',\n",
       " 'jump-care',\n",
       " 'cin√©matographique.Et',\n",
       " 'R√©mie',\n",
       " 'Notre-Dame-de-Paris',\n",
       " 'siroterai',\n",
       " 'Trance-spotting',\n",
       " 't√©moignants',\n",
       " 't√©c√©rath',\n",
       " \"l'Est√©rel\",\n",
       " 'd√©tectives',\n",
       " 'Dwalin.Sans',\n",
       " 'arri√®re-pens√©',\n",
       " 'Arzeneder',\n",
       " 'areu',\n",
       " 'Bigfoot',\n",
       " 'r√©quisitionn√©s',\n",
       " 'jeunot',\n",
       " 'cbose',\n",
       " 'Marivaux‚Ä¶et',\n",
       " 'diversifi√©s',\n",
       " \"d'Osborn\",\n",
       " 'Confite',\n",
       " 'Siman',\n",
       " 'soixante-quatre',\n",
       " 'confiserie',\n",
       " 'scharzy',\n",
       " 'THERON',\n",
       " 'sonc√©rit√©',\n",
       " \"film.C'est\",\n",
       " \"l'orchid√©e\",\n",
       " 'nous-m√™mes.Pour',\n",
       " 'Marineland',\n",
       " 'intriqu√©e',\n",
       " 'coproduction',\n",
       " 'Nidavellir',\n",
       " 'collaborant',\n",
       " 'sans-√™tre',\n",
       " 'salade',\n",
       " 'J¬ß',\n",
       " 'potier',\n",
       " 'jolliiiie',\n",
       " 'raconter‚Ä¶Entre',\n",
       " \"qu'Atiq\",\n",
       " 'elle-m√™me.Ne',\n",
       " 'Samie',\n",
       " \"m'int√©ressaient\",\n",
       " 'Marv',\n",
       " 'Niesson',\n",
       " 'g√©n√©ration.A',\n",
       " 'cam√©ra-transe',\n",
       " 'bobocratie-parisiano-critique',\n",
       " 'c√©l√®ste',\n",
       " 'Phrase',\n",
       " 'collocataires',\n",
       " 'Dam',\n",
       " 'Christia',\n",
       " 'beautyful',\n",
       " 'd√©chiqueteuse',\n",
       " 'senblables',\n",
       " 'Weller',\n",
       " 'cam√©ra‚Ä¶peu',\n",
       " 'mi-Psychologique',\n",
       " 'n√©faste.Marie',\n",
       " 'suicid√®rent',\n",
       " '1,39',\n",
       " 'demeurent',\n",
       " 'Ennasr',\n",
       " 'script√©e',\n",
       " 'moderne.Superbe',\n",
       " 'stukas',\n",
       " 'injonctions',\n",
       " 'sUicc√®s',\n",
       " 'solo.Quant',\n",
       " 'PLutot',\n",
       " 'Hallal',\n",
       " 'per√ßois',\n",
       " 'militaro-pharmaceutique',\n",
       " 'miss-m√©t√©o',\n",
       " 'Kriste',\n",
       " 'films/saga',\n",
       " 'Tegel',\n",
       " 'TOp',\n",
       " 'coup.Quel',\n",
       " 'phallo',\n",
       " '-exceptionnel',\n",
       " 'deviennent-ils',\n",
       " 'tetrouve',\n",
       " 'Multipliant',\n",
       " 'compl√©t√©',\n",
       " 'bachote',\n",
       " 'dumber',\n",
       " 'Grignotez',\n",
       " 'LOURDEUR',\n",
       " 'Archinul',\n",
       " '=sa',\n",
       " 'glorification',\n",
       " 'rebut√©e',\n",
       " \"l'√©blouissement\",\n",
       " 'bonniche',\n",
       " \"d'arnaque.la\",\n",
       " \"L'enigme\",\n",
       " 'specifict√©',\n",
       " 'huniers',\n",
       " '2012-dÔøΩbut',\n",
       " 'noement',\n",
       " \"qu'Oliver\",\n",
       " 'beaucoup.courrez-y',\n",
       " 'couapbles',\n",
       " 'Capoeira',\n",
       " 'Blanc-Bonnet',\n",
       " 'CCS',\n",
       " 'montagne/montagne',\n",
       " 'mi-po√©tique',\n",
       " 'bourn',\n",
       " 'gentirobot',\n",
       " 'visuellement.Parfois',\n",
       " 'Hopkis',\n",
       " 'Denarnaud',\n",
       " 'manquiez',\n",
       " 'Woodley',\n",
       " 'renseign√©s',\n",
       " \"l'h√©ro√Øne/\",\n",
       " 'KURYLENKO',\n",
       " '.plus',\n",
       " 'H√©t√©rosexuelle',\n",
       " 'happend',\n",
       " 'canap√®',\n",
       " 'r√©form√©s',\n",
       " 'souffreteux',\n",
       " 'Divergents‚Ä¶et',\n",
       " 'Domingas',\n",
       " 'forceps',\n",
       " 'Reyjavik',\n",
       " 'embarquee',\n",
       " \"l'bris\",\n",
       " '2014-',\n",
       " \"L'OMBRE\",\n",
       " 'allit√©rations',\n",
       " \"l'apr√©√ßier\",\n",
       " 'photojournalistes',\n",
       " 'Robbins/Eddie',\n",
       " 'pass√¢t',\n",
       " 'acolytes/potes',\n",
       " 'para√Ætres',\n",
       " 'd√®pend',\n",
       " 'amoncellent',\n",
       " 'freefight',\n",
       " 'Bate',\n",
       " 'Chanwook',\n",
       " 'pupilles',\n",
       " 'milice',\n",
       " 'atlante',\n",
       " 'personnalit√©',\n",
       " 'disparaissant',\n",
       " 'd√©courager',\n",
       " 'revendicatif',\n",
       " 'sc√©nographiant',\n",
       " 'emploi.Film',\n",
       " 'rencarder',\n",
       " 'ganter',\n",
       " 'midway',\n",
       " 'semi-drame',\n",
       " \"s'affranchissant\",\n",
       " 'disparaitre.De',\n",
       " 'linguistiques',\n",
       " 'ZiYi',\n",
       " 'L√¢',\n",
       " 'Shazhana',\n",
       " 'charognes',\n",
       " \"L'importance\",\n",
       " 'BlackWidow',\n",
       " 'Caluire',\n",
       " 'CHRISTOF',\n",
       " 'apesante',\n",
       " 'genre.Pour',\n",
       " 'discern√©e',\n",
       " 'r√©int√©rpretter',\n",
       " 'bachelier',\n",
       " 'redire‚Ä¶',\n",
       " 'Donnellan/Nick',\n",
       " 'Marijuana',\n",
       " 'pourraient-il',\n",
       " 'profondeur.O√π',\n",
       " \"s'√©pure\",\n",
       " 's¬¥il',\n",
       " 'Stranley',\n",
       " 'Mud‚Ä¶',\n",
       " 'Fer-blanc',\n",
       " 'dispra√Æt',\n",
       " 'Plante',\n",
       " 'reconquerit',\n",
       " 'Isabela',\n",
       " 'noireaude',\n",
       " 'PANINI',\n",
       " 'pi√®ge-l√†',\n",
       " 'provo',\n",
       " 'ennormement',\n",
       " 'NOUVEAUT√â',\n",
       " 'reverance',\n",
       " 'redescendra',\n",
       " 'chaos.Je',\n",
       " 'Gadd',\n",
       " 'papotages',\n",
       " 'Amiti√®s',\n",
       " 'Footloose',\n",
       " 'Mikkelsen‚Ä¶efficace',\n",
       " 'espionnage-passion',\n",
       " 'honte.Franchement',\n",
       " 'Craquements',\n",
       " 'enfilocher',\n",
       " \"d'insaisissables\",\n",
       " 'Lelouch/Dujardin',\n",
       " 'anti-dopage',\n",
       " 'Ejifor',\n",
       " 'film.Comme',\n",
       " 'arrive.La',\n",
       " \"qu'intens√©ment\",\n",
       " 'Fugges',\n",
       " 'premier/s',\n",
       " \"J'attend\",\n",
       " 'DEMAAAAGOOOGIIIIIIE',\n",
       " 'cuin√©',\n",
       " \"J'enl√®ve\",\n",
       " 'n√©ogothique',\n",
       " 'shoot',\n",
       " 'circonscrite',\n",
       " \"d'√âlodie\",\n",
       " 'decid√©ment',\n",
       " 'restiant',\n",
       " \"'Lascia\",\n",
       " 'NSTB',\n",
       " 'g√©opolisation',\n",
       " 'film‚Ä¶grand',\n",
       " 'b√™tises.Ca',\n",
       " 'd√©finies',\n",
       " '.saga',\n",
       " 'aveu',\n",
       " 'convictions/en',\n",
       " \"d'inhabituel\",\n",
       " 'd√©cidait',\n",
       " 'Found-Footage',\n",
       " 'Blackbriar',\n",
       " 'cin√©ma-l√†',\n",
       " \"qu'in\",\n",
       " 'Donnant',\n",
       " 's√©paratiste',\n",
       " 'flou√©es',\n",
       " 'Fitness',\n",
       " 'Inutile.1h40',\n",
       " 'bol',\n",
       " 'superficielel',\n",
       " 'Beausejour',\n",
       " 'd√©sesp√®reraient',\n",
       " 'russes‚Ä¶',\n",
       " 'propoe',\n",
       " ',je',\n",
       " 'coordinateurs',\n",
       " 'Panamera',\n",
       " 'vandecamp',\n",
       " 's√©rieuse',\n",
       " 'situations-gagues',\n",
       " \"j'vai\",\n",
       " 'bissextiles',\n",
       " 'fellationnaire',\n",
       " 'claustrog√®ne',\n",
       " 'laique',\n",
       " 'Tf1',\n",
       " 'Felipe',\n",
       " 'visonnage',\n",
       " 'pr√©c√©da',\n",
       " 'rgand',\n",
       " 'd√©sol√©s',\n",
       " 'saille',\n",
       " 'Waren',\n",
       " \"qu'apprendre\",\n",
       " \"L'objet\",\n",
       " 'catastrophait',\n",
       " \"d'agissement\",\n",
       " 'obcures',\n",
       " '17h30',\n",
       " 'A.Dupontel-acteur',\n",
       " 'hommes-framboises',\n",
       " 'Enchain√©',\n",
       " '100mins',\n",
       " 'furibarde',\n",
       " \"d'Egypte\",\n",
       " 'non-enfant',\n",
       " 'bouger',\n",
       " 'sonnerait-elle',\n",
       " \"d'escarmouches\",\n",
       " \"d'Herzog\",\n",
       " 'toilett√©s',\n",
       " 'hyper-r√©f√©renc√©e',\n",
       " 'remix',\n",
       " \"n'interviennent\",\n",
       " 'commensurable',\n",
       " 'animalisation',\n",
       " \"s'etreignent\",\n",
       " 'Farr',\n",
       " 'cicatrises',\n",
       " 'boules-quies',\n",
       " 'bosser',\n",
       " 'claqu√©',\n",
       " 'pompeur',\n",
       " \"l'√©blouissante\",\n",
       " \"'n'est\",\n",
       " 'caract√©rose',\n",
       " 'db',\n",
       " 'PIF',\n",
       " 'spacieuse',\n",
       " 'pseudos-h√©ros-bobos',\n",
       " 'inspiree',\n",
       " '//lackingfeather.blogspot.com/2010/11/critique-unstoppable.html',\n",
       " 'Beaux-',\n",
       " 'inv√©t√©r√©',\n",
       " 'Maureau',\n",
       " 'bonhomme-ventouse',\n",
       " 'h√¢tez',\n",
       " 'Lorenzo',\n",
       " 'mini-van',\n",
       " 'Lost-',\n",
       " 'arch√©typale',\n",
       " \"l'arigo\",\n",
       " 'ratonnades',\n",
       " 'fin.La',\n",
       " 'Consid√®r√®',\n",
       " 'pr√©venants',\n",
       " 'l√©zards/humains',\n",
       " 'fr√©missant',\n",
       " 'Mmddrr',\n",
       " 'acteur/agent',\n",
       " 'h√©lant',\n",
       " 'r√©aliser.Si',\n",
       " 'plantueuse',\n",
       " 'annihil√©e',\n",
       " 'passiant.je',\n",
       " 'Dixon‚Ä¶',\n",
       " 'mettrais-je',\n",
       " \"d'allumage\",\n",
       " 'Shimosawa',\n",
       " 'cr√©ature=espoir',\n",
       " 'Walter/Sean',\n",
       " 're-mobilisation',\n",
       " \"beau.J'avais\",\n",
       " \"chez-d'≈ìuvre\",\n",
       " \"n'amorce\",\n",
       " 'derniervolet',\n",
       " 'physiquement',\n",
       " 'enmenn√©',\n",
       " 'amph√©ts',\n",
       " '√©l√©mentaire',\n",
       " 'amis/boulot',\n",
       " 'diagonal',\n",
       " 'comence',\n",
       " 'laisser-pour-compte',\n",
       " 'jeunes-vieux',\n",
       " 'pelet√©e',\n",
       " 'interMinables',\n",
       " 'transfronti√®res',\n",
       " 'Joon',\n",
       " 'CO2',\n",
       " 'd√©couvertes‚Ä¶',\n",
       " 'r√¥tis',\n",
       " 'LOOOOOL',\n",
       " 'combis',\n",
       " 'apur√©s',\n",
       " 'personnages-clefs',\n",
       " 'solidaire/communautaire',\n",
       " 'FILMSANCTU',\n",
       " 'suite.Globalement',\n",
       " \"'Feel\",\n",
       " 'Maigrelette',\n",
       " 'gousse',\n",
       " 'b√¢illonne',\n",
       " 'Cheshire',\n",
       " 'Kodomo',\n",
       " 'Davies',\n",
       " 'abstenais',\n",
       " 'bacle√©',\n",
       " 'TRIERS',\n",
       " '616',\n",
       " 'Avia',\n",
       " 'exiter',\n",
       " 'Requa',\n",
       " 'inf√©rieure',\n",
       " 'pr√©tend',\n",
       " 'archet',\n",
       " 'D17',\n",
       " 'pauvres.Le',\n",
       " 'pr√©cepteur',\n",
       " 'Brolin-Clooney',\n",
       " 'BPI',\n",
       " \"l'indigestion.Certes\",\n",
       " 'simplicit√©‚Ä¶.Autant',\n",
       " 'telephonne',\n",
       " 'Pe√±a',\n",
       " \"m'√©talerai\",\n",
       " 'reenforce',\n",
       " 'surprotectrice',\n",
       " 'ANNABELLA',\n",
       " 'Rhinoplastie',\n",
       " \"d'anneries\",\n",
       " 'viencent',\n",
       " 'pseudo-cynisme',\n",
       " 'concede',\n",
       " 'Minecraft',\n",
       " 'fordiens',\n",
       " \"s'allonger\",\n",
       " 'ing√©nument',\n",
       " 'bidonn√©es',\n",
       " 'd√©placaient',\n",
       " 'patritotes',\n",
       " 'impotente',\n",
       " 'int√©ressant',\n",
       " 'n√©oclassique',\n",
       " 'StarLords',\n",
       " 'Poublots',\n",
       " 'Hellblazer',\n",
       " '√©panouiront',\n",
       " \"n'accompagnera\",\n",
       " 'barbarian',\n",
       " 'rapetisse-le',\n",
       " 'soustraction',\n",
       " 'Kirito',\n",
       " 'request',\n",
       " 'fossilisation',\n",
       " 'super-coke',\n",
       " 'premi√®re‚Ä¶',\n",
       " \"l'hypnagogie\",\n",
       " 'Bitzer',\n",
       " 'c√¢ch√©e',\n",
       " 'engag√©‚Ä¶aucune',\n",
       " \"n'ennuyer\",\n",
       " 'cruels‚Ä¶.Ces',\n",
       " 'int√©r√©ss√©s',\n",
       " 'HEADQuant',\n",
       " 'pressur√©s',\n",
       " \"L'asservissement\",\n",
       " 'dC3C3A9A9jouer',\n",
       " 'Super-Nintendo',\n",
       " 'Graig',\n",
       " ...]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexique_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb246e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "import numpy as np\n",
    "\n",
    "def matrice(message, lexique_unique):\n",
    "    h = table_h(lexique_unique)\n",
    "    nombre_lignes = message.shape[0]\n",
    "    nombre_colones = len(h)\n",
    "    \n",
    "    # Utilisation d'une matrice creuse\n",
    "    m = lil_matrix((nombre_lignes, nombre_colones), dtype=np.float32)\n",
    "\n",
    "    for i in range(nombre_lignes):\n",
    "        for mot in lexique_unique:\n",
    "            if mot in message[i]:  # Seulement traiter si le mot est dans le message\n",
    "                j = h[mot]\n",
    "                mot += \" \"\n",
    "                nombre_occurence = message[i].count(mot)\n",
    "                m[i, j] = nombre_occurence\n",
    "\n",
    "    print(\"fin de la foncrion\\n\") \n",
    "    return m.tocsr()  # Convertir en format CSR pour une meilleure efficacit√©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5dd3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creaton de la matrice\n",
    "#donnees_train= matrice(message_train,lexique_unique)\n",
    "#donnees_test= matrice(message_test,lexique_unique)\n",
    "donnees_dev= matrice(message_dev,lexique_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5130d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees_train= matrice(message_train,lexique_unique)\n",
    "donnees_test= matrice(message_test,lexique_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe2aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format accepter par svm\n",
    "svm_train = convertir_svm(donnees_train , label_train )\n",
    "svm_test = convertir_svm(donnees_test , label_test )\n",
    "svm_dev = convertir_svm(donnees_dev , label_dev )\n",
    "\n",
    "#ecrire dans le fichier\n",
    "file(\"train.svm\",svm_train)\n",
    "file(\"test.svm\",svm_test)\n",
    "file(\"dev.svm\",svm_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d988a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
