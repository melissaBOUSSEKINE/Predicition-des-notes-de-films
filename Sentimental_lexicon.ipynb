{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElTj8ByRHIYK",
        "outputId": "c41a6f7f-5f32-4422-82cb-09bfa78fe64b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import operator as op\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk"
      ],
      "metadata": {
        "id": "sQM57Z99Nuun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_train = '/content/drive/My Drive/Analyse_des_sentiment/data/train.xml'\n",
        "file_dev   = '/content/drive/My Drive/Analyse_des_sentiment/data/dev.xml'\n",
        "file_test  = '/content/drive/My Drive/Analyse_des_sentiment/data/test.xml'"
      ],
      "metadata": {
        "id": "temRoGOMNeYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_xml_to_dataframe(file_path):\n",
        "    # Analyse du fichier XML\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Création d'une liste vide pour stocker les données\n",
        "    data = []\n",
        "\n",
        "    # Parcours des éléments de commentaire\n",
        "    for comment in root.findall('comment'):\n",
        "        movie = comment.find('movie').text\n",
        "        review_id = comment.find('review_id').text\n",
        "        name = comment.find('name').text\n",
        "        user_id = comment.find('user_id').text\n",
        "        note = comment.find('note').text.replace(',', '.')\n",
        "        commentaire = comment.find('commentaire').text\n",
        "\n",
        "        # Ajout des données dans la liste sous forme de dictionnaire\n",
        "        data.append({\n",
        "            'movie': movie,\n",
        "            'review_id': review_id,\n",
        "            'name': name,\n",
        "            'user_id': user_id,\n",
        "            'note': note,\n",
        "            'commentaire': commentaire\n",
        "        })\n",
        "\n",
        "    # Création d'un DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    return df"
      ],
      "metadata": {
        "id": "EDhcQKisNjA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fonction pour le fichier de test\n",
        "def read_xml_to_dataframeTest(file_path):\n",
        "    # Analyse du fichier XML\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Création d'une liste vide pour stocker les données\n",
        "    data = []\n",
        "\n",
        "    # Parcours des éléments de commentaire\n",
        "    for comment in root.findall('comment'):\n",
        "        # Initialisation d'un dictionnaire pour chaque commentaire\n",
        "        comment_data = {}\n",
        "\n",
        "        # Extraction de chaque élément si disponible et ajout au dictionnaire\n",
        "        movie = comment.find('movie')\n",
        "        if movie is not None:\n",
        "            comment_data['movie'] = movie.text\n",
        "\n",
        "        review_id = comment.find('review_id')\n",
        "        if review_id is not None:\n",
        "            comment_data['review_id'] = review_id.text\n",
        "\n",
        "        name = comment.find('name')\n",
        "        if name is not None:\n",
        "            comment_data['name'] = name.text\n",
        "\n",
        "        user_id = comment.find('user_id')\n",
        "        if user_id is not None:\n",
        "            comment_data['user_id'] = user_id.text\n",
        "\n",
        "\n",
        "        note = comment.find('note')\n",
        "        if note is not None:\n",
        "            comment_data['note'] = note.text.replace(',', '.')\n",
        "\n",
        "        commentaire = comment.find('commentaire')\n",
        "        if commentaire is not None:\n",
        "            comment_data['commentaire'] = commentaire.text\n",
        "\n",
        "        # Ajout des données dans la liste sous forme de dictionnaire\n",
        "        data.append(comment_data)\n",
        "\n",
        "    # Création d'un DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "5IiDudSXNj-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Récupération des données dans des dataFrame\"\"\"\n",
        "\n",
        "#création DataFrame\n",
        "data_dev   = read_xml_to_dataframe(file_dev)\n",
        "data_train = read_xml_to_dataframe(file_train)\n",
        "data_test = read_xml_to_dataframeTest(file_test)\n"
      ],
      "metadata": {
        "id": "7ReU4pz_No3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/My Drive/processed_data/POLARITY-JEUXDEMOTS-FR.csv'\n",
        "temp_file_path = '/content/drive/My Drive/processed_data/temp_lexicon.csv'\n",
        "\n",
        "\n",
        "data = []\n",
        "\n",
        "with open(file_path, 'r', encoding='latin1') as file:\n",
        "    for line in file:\n",
        "        if line.startswith('//'):  # Check for comment line\n",
        "            continue\n",
        "\n",
        "        # Split the line by semicolon, but not those inside quotes\n",
        "        parts = line.strip().split(';')\n",
        "\n",
        "        # Handle each part\n",
        "        if len(parts) == 5:\n",
        "            line_number, term, positive, neutral, negative = parts\n",
        "            # Remove quotes from term if present\n",
        "            term = term.strip('\"')\n",
        "            data.append([line_number, term, positive, neutral, negative])\n",
        "\n",
        "# Convert the list of data into a DataFrame\n",
        "lexicon_df = pd.DataFrame(data, columns=['line_number', 'term', 'positive', 'neutral', 'negative'])\n",
        "\n",
        "# Create a dictionary mapping terms to their sentiment scores\n",
        "sentiment_lexicon = {\n",
        "    term: {\n",
        "        'positive': int(row['positive']),\n",
        "        'negative': int(row['negative']),\n",
        "        'neutral': int(row['neutral'])\n",
        "    }\n",
        "    for term, row in lexicon_df.iterrows() if row['term'] not in ['terme', '']\n",
        "}\n",
        "\n",
        "# Display the DataFrame to verify\n",
        "print(lexicon_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWNFJyOjHGF6",
        "outputId": "a847c0d9-6f18-47ec-df1f-fdf01a3d46c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       line_number         term positive neutral negative\n",
            "0                1            =       75      37       31\n",
            "1                2           =)      236      47        0\n",
            "2                3            >       22      21       21\n",
            "3                4            -      381      49       74\n",
            "4                5           -é       68     245        0\n",
            "...            ...          ...      ...     ...      ...\n",
            "642378      642883      Z>Zorro       98      61        0\n",
            "642379      642884       ZZ Top      269      58       38\n",
            "642380      642885          zzz      108     115      105\n",
            "642381      642886   zzz>dormir        3       2        2\n",
            "642382      642887  zzz>insecte        3       2        2\n",
            "\n",
            "[642383 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCtmL4QVCFmr"
      },
      "outputs": [],
      "source": [
        "def get_sentiment_score(document):\n",
        "    positive_score = 0\n",
        "    negative_score = 0\n",
        "    neutral_score = 0\n",
        "\n",
        "    words = document.split()  # Split into words\n",
        "    for word in words:\n",
        "        if word in sentiment_lexicon:\n",
        "            sentiment = sentiment_lexicon[word]\n",
        "            positive_score += sentiment['positive']\n",
        "            negative_score += sentiment['negative']\n",
        "            neutral_score += sentiment['neutral']\n",
        "\n",
        "    total_score = positive_score - negative_score + neutral_score\n",
        "    return total_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_train = data_train.dropna(subset=['commentaire'])\n",
        "data_dev = data_dev.dropna(subset=['commentaire'])\n",
        "data_test = data_test.dropna(subset=['commentaire'])"
      ],
      "metadata": {
        "id": "tZuwohzCMWq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train['sentiment_score'] = data_train['commentaire'].apply(get_sentiment_score)\n",
        "data_dev['sentiment_score'] = data_dev['commentaire'].apply(get_sentiment_score)\n",
        "data_test['sentiment_score'] = data_test['commentaire'].apply(get_sentiment_score)\n"
      ],
      "metadata": {
        "id": "5yuGYvuQNXtF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}